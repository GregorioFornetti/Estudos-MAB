{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"/workspace/gregorio/reinforcement-learning-recsys/1-datasets/bestbuy/interactions.csv\", sep=';')\n",
    "    df = df.rename(columns={\n",
    "        'id_user': 'user_id',\n",
    "        'id_item': 'item_id',\n",
    "    })\n",
    "    df['response'] = 1\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    df = df[['user_id', 'item_id', 'response']]\n",
    "    df = df.iloc[:int(len(df) * 0.5)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>496cde27a7d6a3d4989c8a7143f7a7573dcad18e</td>\n",
       "      <td>1658122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9efe144125a01b1ed7301e9cba939a3f3f33ef13</td>\n",
       "      <td>2969477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c83a96b80b0fb276a93ec8b5c3cc9df57f53914d</td>\n",
       "      <td>999996500050001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ba3fb6612eb4f198673be714dde48d14d2f9d3c</td>\n",
       "      <td>9999161700050000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2059e46ae923f4227600e8edb620ae898bd30d7d</td>\n",
       "      <td>1283795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932629</th>\n",
       "      <td>9ced14c84a3acea31f672863b992db9d318c0b8f</td>\n",
       "      <td>3247045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932630</th>\n",
       "      <td>7e0ab19bfacd80395955d81dd079fc185436802b</td>\n",
       "      <td>3340175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932631</th>\n",
       "      <td>8819d0cd0ba5e78674143ad1bd2ec814f6ff4de8</td>\n",
       "      <td>1708812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932632</th>\n",
       "      <td>ac10df6cb48036e5cdd73e9e56e9d954680e7a74</td>\n",
       "      <td>2052149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932633</th>\n",
       "      <td>b4406b264576874fd978ecb632336f3362697a30</td>\n",
       "      <td>2684193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932634 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_id           item_id  response\n",
       "0       496cde27a7d6a3d4989c8a7143f7a7573dcad18e           1658122         1\n",
       "1       9efe144125a01b1ed7301e9cba939a3f3f33ef13           2969477         1\n",
       "2       c83a96b80b0fb276a93ec8b5c3cc9df57f53914d   999996500050001         1\n",
       "3       3ba3fb6612eb4f198673be714dde48d14d2f9d3c  9999161700050000         1\n",
       "4       2059e46ae923f4227600e8edb620ae898bd30d7d           1283795         1\n",
       "...                                          ...               ...       ...\n",
       "932629  9ced14c84a3acea31f672863b992db9d318c0b8f           3247045         1\n",
       "932630  7e0ab19bfacd80395955d81dd079fc185436802b           3340175         1\n",
       "932631  8819d0cd0ba5e78674143ad1bd2ec814f6ff4de8           1708812         1\n",
       "932632  ac10df6cb48036e5cdd73e9e56e9d954680e7a74           2052149         1\n",
       "932633  b4406b264576874fd978ecb632336f3362697a30           2684193         1\n",
       "\n",
       "[932634 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando os modelos MAB usando concatenações de diferentes formas de fazer o contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregorio/.conda/envs/weighted-sims/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gregorio/.conda/envs/weighted-sims/lib/python3.8/site-packages/implicit/gpu/__init__.py:13: UserWarning: CUDA extension is built, but disabling GPU support because of 'Cuda Error: no CUDA-capable device is detected (/project/./implicit/gpu/utils.h:71)'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "import plotly.express as px\n",
    "import time\n",
    "import os\n",
    "import implicit\n",
    "from mab2rec import BanditRecommender, LearningPolicy\n",
    "\n",
    "train_data = \"../data/ml100k/data_train.csv\"\n",
    "test_data = \"../data/ml100k/data_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_embeddings_model(Model, df, num_users, num_items, generate_embeddings=False):\n",
    "    sparse_matrix = csr_matrix((df['response'], (df['user_id'], df['item_id'])), shape=(num_users, num_items))\n",
    "\n",
    "    model = Model(factors=FACTORS, random_state=1, num_threads=1)\n",
    "    model.fit(sparse_matrix)\n",
    "\n",
    "    if not generate_embeddings:\n",
    "        return model, sparse_matrix\n",
    "    \n",
    "    # # Não precisamos mais do código abaixo, ele funcina para embeddings de usuário, não de itens\n",
    "    # user_features_list = []\n",
    "\n",
    "    # for user_id in df['user_id'].unique():\n",
    "    #    user_factors = model.user_factors[user_id][:FACTORS]  # O BPR coloca 1 no final dos vetores latentes ?\n",
    "    #    user_features_list.append([user_id] + list(user_factors))\n",
    "\n",
    "    # df_user_features = pd.DataFrame(user_features_list, columns=['user_id'] + [f'u{i}' for i in range(FACTORS)])\n",
    "\n",
    "    # model = model.to_cpu()\n",
    "    return model, sparse_matrix, model.item_factors, model.user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_embeddings_model(model, sparse_matrix, df_test):\n",
    "    all_recs = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    hits = 0\n",
    "    for _, interaction in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "        ids_recs, _ = model.recommend(userid=interaction['user_id'], user_items=sparse_matrix[interaction['user_id']], N=10)\n",
    "        if interaction['item_id'] in ids_recs:\n",
    "            hits += 1\n",
    "        all_recs.append(ids_recs.tolist())\n",
    "    \n",
    "    recs_df = pd.DataFrame({\n",
    "        'interaction_number': [i for i in range(len(df_test))],\n",
    "        'user_id': df_test['user_id'],\n",
    "        'item_id': df_test['item_id'],\n",
    "        'recommendations': all_recs\n",
    "    })\n",
    "    \n",
    "    return hits, hits/len(df_test), time.time() - start_time, recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_mab(mab_algo, df_train_with_contexts, contexts_col):\n",
    "    contexts = get_concat_context(df_train_with_contexts, contexts_col)\n",
    "    mab_algo.fit(\n",
    "        decisions=df_train_with_contexts['item_id'],\n",
    "        rewards=df_train_with_contexts['response'],\n",
    "        contexts=contexts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_non_incremental(mab_algo, contexts_col, df_test, interactions_by_user):\n",
    "    start_time = time.time()\n",
    "    hits = 0\n",
    "\n",
    "    # contexts = df_test.merge(user_features, how='left', on='user_id').drop(columns=['user_id', 'item_id', 'response']).values\n",
    "    # contexts = np.array(df_test[contexts_col].tolist())\n",
    "    print('entrou')\n",
    "    contexts = get_concat_context(df_test, contexts_col)\n",
    "    filters = df_test.merge(interactions_by_user, how='left', on='user_id')[['interactions']].values.squeeze(axis=1) \n",
    "    print('saiu')\n",
    "\n",
    "    recomendations = mab_algo.recommend(contexts, filters, apply_sigmoid=False)\n",
    "\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    hits = 0\n",
    "    for i, interaction in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "        if interaction['item_id'] in recomendations[i]:\n",
    "            hits += 1\n",
    "    \n",
    "\n",
    "    recs_df = pd.DataFrame({\n",
    "        'interaction_number': [i for i in range(len(df_test))],\n",
    "        'user_id': df_test['user_id'],\n",
    "        'item_id': df_test['item_id'],\n",
    "        'recommendations': recomendations\n",
    "    })\n",
    "\n",
    "    return hits, hits/len(df_test), time.time() - start_time, recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_interactions_by_user(interactions_df):\n",
    "    interactions_by_user = interactions_df\\\n",
    "                        .groupby('user_id')[['item_id']]\\\n",
    "                        .apply(lambda df_user: df_user['item_id'].tolist())\\\n",
    "                        .reset_index(name='interactions')\n",
    "    interactions_by_user = interactions_by_user.reset_index(drop=True)\n",
    "    return interactions_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_list_items_mean(interactions_df, items_embeddings):\n",
    "    users_current_info = {}\n",
    "    contexts = []\n",
    "\n",
    "    for _, row in tqdm(interactions_df.iterrows(), total=len(interactions_df)):\n",
    "        user_id = row[\"user_id\"]\n",
    "        item_id = row[\"item_id\"]\n",
    "\n",
    "        if user_id not in users_current_info:\n",
    "            users_current_info[user_id] = {\n",
    "                'acum_emb': np.zeros((items_embeddings.shape[1], )),\n",
    "                'count': 0\n",
    "            }\n",
    "        \n",
    "        contexts.append(users_current_info[user_id]['acum_emb'] / max(1, users_current_info[user_id]['count']))\n",
    "\n",
    "        users_current_info[user_id]['acum_emb'] += items_embeddings[item_id][:items_embeddings.shape[1]]\n",
    "        users_current_info[user_id]['count'] += 1\n",
    "\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_list_items_concat(interactions_df, items_embeddings, window_size):\n",
    "    users_current_info = {}\n",
    "    contexts = []\n",
    "\n",
    "    for _, row in interactions_df.iterrows():\n",
    "        user_id = row[\"user_id\"]\n",
    "        item_id = row[\"item_id\"]\n",
    "\n",
    "        if user_id not in users_current_info:\n",
    "            users_current_info[user_id] = np.zeros((window_size, items_embeddings.shape[1]))\n",
    "        \n",
    "        contexts.append(users_current_info[user_id].flatten())\n",
    "        \n",
    "        users_current_info[user_id][1:] = users_current_info[user_id][:-1]\n",
    "        users_current_info[user_id][0] = items_embeddings[item_id][:items_embeddings.shape[1]]\n",
    "\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_list_user(interactions_df, users_embeddings):\n",
    "    contexts = []\n",
    "\n",
    "    for _, row in interactions_df.iterrows():\n",
    "        user_id = row[\"user_id\"]\n",
    "        contexts.append(users_embeddings[user_id][:users_embeddings.shape[1]])\n",
    "\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_context(interactions, context_cols):\n",
    "    # Concat multiple array columns into a single array column\n",
    "    return np.array(interactions[context_cols].apply(lambda x: np.concatenate((*x, [1])), axis=1).tolist())  # MUDANÇA: adiciona 1 ao final de cada vetor (bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mabwiser.linear import _Linear\n",
    "from mabwiser.utils import Num, _BaseRNG\n",
    "from typing import List, Optional\n",
    "\n",
    "class _LinearArmEncoded(_Linear):\n",
    "\n",
    "    def __init__(self, rng: _BaseRNG, num_arms: int, n_jobs: int, backend: Optional[str],\n",
    "                 alpha: Num, epsilon: Num, l2_lambda: Num, regression: str, scale: bool):\n",
    "        super().__init__(rng, np.arange(num_arms).tolist(), n_jobs, backend, alpha, epsilon, l2_lambda, regression, scale)\n",
    "        self.num_arms = num_arms\n",
    "    \n",
    "    def _vectorized_predict_context(self, contexts: np.ndarray, is_predict: bool) -> List:\n",
    "\n",
    "        arms = np.arange(self.num_arms)\n",
    "\n",
    "        # Initializing array with expectations for each arm\n",
    "        num_contexts = contexts.shape[0]\n",
    "        arm_expectations = np.empty((num_contexts, self.num_arms), dtype=float)\n",
    "\n",
    "        # With epsilon probability, assign random flag to context\n",
    "        random_values = self.rng.rand(num_contexts)\n",
    "        print('random values')\n",
    "        print(random_values)\n",
    "        random_mask = np.array(random_values < self.epsilon)\n",
    "        random_indices = random_mask.nonzero()[0]\n",
    "\n",
    "        # For random indices, generate random expectations\n",
    "        arm_expectations[random_indices] = self.rng.rand((random_indices.shape[0], self.num_arms))\n",
    "\n",
    "        # For non-random indices, get expectations for each arm\n",
    "        nonrandom_indices = np.where(~random_mask)[0]\n",
    "        nonrandom_context = contexts[nonrandom_indices]\n",
    "        print('Gerando as predições')\n",
    "        start_time = time.time()\n",
    "        arm_expectations[nonrandom_indices] = np.array([self.arm_to_model[arm].predict(nonrandom_context)\n",
    "                                                        for arm in arms]).T\n",
    "        print(f'Gerar as predições demorou {time.time() - start_time} segundos')\n",
    "\n",
    "        return arm_expectations if len(arm_expectations) > 1 else arm_expectations[0]\n",
    "    \n",
    "    def fit(self, decisions: np.ndarray, rewards: np.ndarray, contexts: np.ndarray = None) -> None:\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Initialize each model by arm\n",
    "        self.num_features = contexts.shape[1]\n",
    "        for arm in self.arms:\n",
    "            self.arm_to_model[arm].init(num_features=self.num_features)\n",
    "        print(f'arm_to_model demorou {start_time - time.time()}')\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Reset warm started arms\n",
    "        # self._reset_arm_to_status()\n",
    "        print(f'reset_arm_to_status demorou {start_time - time.time()}')\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Perform parallel fit\n",
    "        self._parallel_fit(decisions, rewards, contexts)\n",
    "        print(f'paralel fit demorou {start_time - time.time()}')\n",
    "\n",
    "        # Update trained arms\n",
    "        start_time = time.time()\n",
    "        # Removi o código abaixo pois parece que ele não é usado para o nosso caso...\n",
    "        # Ele parece ser usado apenas no contexto de tentar fazer \"warm\" start\n",
    "        # Basicamente, copiando os mesmos parâmetros de um arm já treinado para um novo (cold) por proximidade de features...\n",
    "\n",
    "        # Otimizar essa função não parece ser algo tão trivial, já que teria que mudar a estrutura do arm_to_status, tendo que mudar vários outros códigos por causa disso\n",
    "        # self._set_arms_as_trained(decisions=decisions, is_partial=False)\n",
    "        print(f'_set_arms_as_trained acabou em {start_time - time.time()} segundos')\n",
    "    \n",
    "    def partial_fit(self, decisions: np.ndarray, rewards: np.ndarray, contexts: np.ndarray = None) -> None:\n",
    "        # Perform parallel fit\n",
    "        self._parallel_fit(decisions, rewards, contexts)\n",
    "\n",
    "        # Update trained arms\n",
    "        # self._set_arms_as_trained(decisions=decisions, is_partial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mabwiser.mab import MAB, LearningPolicyType, NeighborhoodPolicyType, NeighborhoodPolicy\n",
    "from typing import List\n",
    "\n",
    "from mabwiser._version import __author__, __copyright__, __email__, __version__\n",
    "from mabwiser.approximate import _LSHNearest\n",
    "from mabwiser.clusters import _Clusters\n",
    "from mabwiser.greedy import _EpsilonGreedy\n",
    "from mabwiser.linear import _Linear\n",
    "from mabwiser.neighbors import _KNearest, _Radius\n",
    "from mabwiser.popularity import _Popularity\n",
    "from mabwiser.rand import _Random\n",
    "from mabwiser.softmax import _Softmax\n",
    "from mabwiser.thompson import _ThompsonSampling\n",
    "from mabwiser.treebandit import _TreeBandit\n",
    "from mabwiser.ucb import _UCB1\n",
    "from mabwiser.utils import Arm, Constants, check_true, create_rng\n",
    "\n",
    "class MABArmEncoded(MAB):\n",
    "    def __init__(self,\n",
    "                 num_arms: int,  # The list of arms\n",
    "                 learning_policy: LearningPolicyType,  # The learning policy\n",
    "                 neighborhood_policy: NeighborhoodPolicyType = None,  # The context policy, optional\n",
    "                 seed: int = Constants.default_seed,  # The random seed\n",
    "                 n_jobs: int = 1,  # Number of parallel jobs\n",
    "                 backend: str = None  # Parallel backend implementation\n",
    "                 ):\n",
    "        \"\"\"Initializes a multi-armed bandit (MAB) with the given arguments.\n",
    "\n",
    "        Validates the arguments and raises exception in case there are violations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        arms : List[Union[int, float, str]]\n",
    "            The list of all the arms available for decisions.\n",
    "            Arms can be integers, strings, etc.\n",
    "        learning_policy : LearningPolicyType\n",
    "            The learning policy.\n",
    "        neighborhood_policy : NeighborhoodPolicyType, optional\n",
    "            The context policy. Default value is None.\n",
    "        seed : numbers.Rational, optional\n",
    "            The random seed to initialize the random number generator.\n",
    "            Default value is set to Constants.default_seed.value\n",
    "        n_jobs: int, optional\n",
    "            This is used to specify how many concurrent processes/threads should be used for parallelized routines.\n",
    "            Default value is set to 1.\n",
    "            If set to -1, all CPUs are used.\n",
    "            If set to -2, all CPUs but one are used, and so on.\n",
    "        backend: str, optional\n",
    "            Specify a parallelization backend implementation supported in the joblib library. Supported options are:\n",
    "            - “loky” used by default, can induce some communication and memory overhead when exchanging input and\n",
    "              output data with the worker Python processes.\n",
    "            - “multiprocessing” previous process-based backend based on multiprocessing.Pool. Less robust than loky.\n",
    "            - “threading” is a very low-overhead backend but it suffers from the Python Global Interpreter Lock if the\n",
    "              called function relies a lot on Python objects.\n",
    "            Default value is None. In this case the default backend selected by joblib will be used.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError:  Arms were not provided in a list.\n",
    "        TypeError:  Learning policy type mismatch.\n",
    "        TypeError:  Context policy type mismatch.\n",
    "        TypeError:  Seed is not an integer.\n",
    "        TypeError:  Number of parallel jobs is not an integer.\n",
    "        TypeError:  Parallel backend is not a string.\n",
    "        TypeError:  For EpsilonGreedy, epsilon must be integer or float.\n",
    "        TypeError:  For LinGreedy, epsilon must be an integer or float.\n",
    "        TypeError:  For LinGreedy, l2_lambda must be an integer or float.\n",
    "        TypeError:  For LinTS, alpha must be an integer or float.\n",
    "        TypeError:  For LinTS, l2_lambda must be an integer or float.\n",
    "        TypeError:  For LinUCB, alpha must be an integer or float.\n",
    "        TypeError:  For LinUCB, l2_lambda must be an integer or float.\n",
    "        TypeError:  For Softmax, tau must be an integer or float.\n",
    "        TypeError:  For ThompsonSampling, binarizer must be a callable function.\n",
    "        TypeError:  For UCB, alpha must be an integer or float.\n",
    "        TypeError:  For LSHNearest, n_dimensions must be an integer or float.\n",
    "        TypeError:  For LSHNearest, n_tables must be an integer or float.\n",
    "        TypeError:  For LSHNearest, no_nhood_prob_of_arm must be None or List that sums up to 1.0.\n",
    "        TypeError:  For Clusters, n_clusters must be an integer.\n",
    "        TypeError:  For Clusters, is_minibatch must be a boolean.\n",
    "        TypeError:  For Radius, radius must be an integer or float.\n",
    "        TypeError:  For Radius, no_nhood_prob_of_arm must be None or List that sums up to 1.0.\n",
    "        TypeError:  For KNearest, k must be an integer or float.\n",
    "\n",
    "        ValueError: Invalid number of arms.\n",
    "        ValueError: Invalid values (None, NaN, Inf) in arms.\n",
    "        ValueError: Duplicate values in arms.\n",
    "        ValueError: Number of parallel jobs is 0.\n",
    "        ValueError: For EpsilonGreedy, epsilon must be between 0 and 1.\n",
    "        ValueError: For LinGreedy, epsilon must be between 0 and 1.\n",
    "        ValueError: For LinGreedy, l2_lambda cannot be negative.\n",
    "        ValueError: For LinTS, alpha must be greater than zero.\n",
    "        ValueError: For LinTS, l2_lambda must be greater than zero.\n",
    "        ValueError: For LinUCB, alpha cannot be negative.\n",
    "        ValueError: For LinUCB, l2_lambda cannot be negative.\n",
    "        ValueError: For Softmax, tau must be greater than zero.\n",
    "        ValueError: For UCB, alpha must be greater than zero.\n",
    "        ValueError: For LSHNearest, n_dimensions must be gerater than zero.\n",
    "        ValueError: For LSHNearest, n_tables must be gerater than zero.\n",
    "        ValueError: For LSHNearest, if given, no_nhood_prob_of_arm list should sum up to 1.0.\n",
    "        ValueError: For Clusters, n_clusters cannot be less than 2.\n",
    "        ValueError: For Radius and KNearest, metric is not supported by scipy.spatial.distance.cdist.\n",
    "        ValueError: For Radius, radius must be greater than zero.\n",
    "        ValueError: For Radius, if given, no_nhood_prob_of_arm list should sum up to 1.0.\n",
    "        ValueError: For KNearest, k must be greater than zero.\n",
    "        \"\"\"\n",
    "\n",
    "        # Validate arguments\n",
    "        # MAB._validate_mab_args(arms, learning_policy, neighborhood_policy, seed, n_jobs, backend)\n",
    "\n",
    "        # Save the arguments\n",
    "        self.arms = np.arange(num_arms)\n",
    "        self.num_arms = num_arms\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs\n",
    "        self.backend = backend\n",
    "\n",
    "        # Create the random number generator\n",
    "        self._rng = create_rng(self.seed)\n",
    "        self._is_initial_fit = False\n",
    "\n",
    "        # Create the learning policy implementor\n",
    "        lp = None\n",
    "        if isinstance(learning_policy, LearningPolicy.EpsilonGreedy):\n",
    "            lp = _EpsilonGreedy(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.epsilon)\n",
    "        elif isinstance(learning_policy, LearningPolicy.Popularity):\n",
    "            lp = _Popularity(self._rng, self.arms, self.n_jobs, self.backend)\n",
    "        elif isinstance(learning_policy, LearningPolicy.Random):\n",
    "            lp = _Random(self._rng, self.arms, self.n_jobs, self.backend)\n",
    "        elif isinstance(learning_policy, LearningPolicy.Softmax):\n",
    "            lp = _Softmax(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.tau)\n",
    "        elif isinstance(learning_policy, LearningPolicy.ThompsonSampling):\n",
    "            lp = _ThompsonSampling(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.binarizer)\n",
    "        elif isinstance(learning_policy, LearningPolicy.UCB1):\n",
    "            lp = _UCB1(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.alpha)\n",
    "        elif isinstance(learning_policy, LearningPolicy.LinGreedy):\n",
    "            lp = _LinearArmEncoded(self._rng, num_arms, self.n_jobs, self.backend, 0, learning_policy.epsilon,\n",
    "                         learning_policy.l2_lambda, \"ridge\", learning_policy.scale)\n",
    "        elif isinstance(learning_policy, LearningPolicy.LinTS):\n",
    "            lp = _LinearArmEncoded(self._rng, num_arms, self.n_jobs, self.backend, learning_policy.alpha, 0,\n",
    "                         learning_policy.l2_lambda, \"ts\", learning_policy.scale)\n",
    "        elif isinstance(learning_policy, LearningPolicy.LinUCB):\n",
    "            lp = _LinearArmEncoded(self._rng, num_arms, self.n_jobs, self.backend, learning_policy.alpha, 0,\n",
    "                         learning_policy.l2_lambda, \"ucb\", learning_policy.scale)\n",
    "        else:\n",
    "            check_true(False, ValueError(\"Undefined learning policy \" + str(learning_policy)))\n",
    "\n",
    "        # Create the mab implementor\n",
    "        if neighborhood_policy:\n",
    "            self.is_contextual = True\n",
    "\n",
    "            # Do not use parallel fit or predict for Learning Policy when contextual\n",
    "            lp.n_jobs = 1\n",
    "\n",
    "            if isinstance(neighborhood_policy, NeighborhoodPolicy.Clusters):\n",
    "                self._imp = _Clusters(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                      neighborhood_policy.n_clusters, neighborhood_policy.is_minibatch)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.LSHNearest):\n",
    "                self._imp = _LSHNearest(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                        neighborhood_policy.n_dimensions, neighborhood_policy.n_tables,\n",
    "                                        neighborhood_policy.no_nhood_prob_of_arm)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.KNearest):\n",
    "                self._imp = _KNearest(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                      neighborhood_policy.k, neighborhood_policy.metric)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.Radius):\n",
    "                self._imp = _Radius(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                    neighborhood_policy.radius, neighborhood_policy.metric,\n",
    "                                    neighborhood_policy.no_nhood_prob_of_arm)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.TreeBandit):\n",
    "                self._imp = _TreeBandit(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                        neighborhood_policy.tree_parameters)\n",
    "            else:\n",
    "                check_true(False, ValueError(\"Undefined context policy \" + str(neighborhood_policy)))\n",
    "        else:\n",
    "            self.is_contextual = isinstance(learning_policy, (LearningPolicy.LinGreedy, LearningPolicy.LinTS,\n",
    "                                                              LearningPolicy.LinUCB))\n",
    "            self._imp = lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Union\n",
    "from mabwiser.utils import Arm, Num, _BaseRNG\n",
    "from scipy.special import expit\n",
    "\n",
    "class BanditRecommenderArmEncoded(BanditRecommender):\n",
    "    def _init(self, num_arms: int) -> None:\n",
    "        \"\"\"Initializes recommender with given list of arms.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        arms : List[Union[Arm]]\n",
    "            The list of all of the arms available for decisions.\n",
    "            Arms can be integers, strings, etc.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Returns nothing\n",
    "        \"\"\"\n",
    "        self.mab = MABArmEncoded(num_arms, self.learning_policy, self.neighborhood_policy, self.seed, self.n_jobs, self.backend)\n",
    "    \n",
    "    def fit(self, decisions: Union[List[Arm], np.ndarray, pd.Series],\n",
    "            rewards: Union[List[Num], np.ndarray, pd.Series],\n",
    "            contexts: Union[None, List[List[Num]], np.ndarray, pd.Series, pd.DataFrame] = None) -> None:\n",
    "        \"\"\"Fits the recommender the given *decisions*, their corresponding *rewards* and *contexts*, if any.\n",
    "        If the recommender arms has not been initialized using the `set_arms`, the recommender arms will be set\n",
    "        to the list of arms in *decisions*.\n",
    "\n",
    "        Validates arguments and raises exceptions in case there are violations.\n",
    "\n",
    "        This function makes the following assumptions:\n",
    "            - each decision corresponds to an arm of the bandit.\n",
    "            - there are no ``None``, ``Nan``, or ``Infinity`` values in the contexts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "         decisions : Union[List[Arm], np.ndarray, pd.Series]\n",
    "            The decisions that are made.\n",
    "         rewards : Union[List[Num], np.ndarray, pd.Series]\n",
    "            The rewards that are received corresponding to the decisions.\n",
    "         contexts : Union[None, List[List[Num]], np.ndarray, pd.Series, pd.DataFrame], default=None\n",
    "            The context under which each decision is made.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Returns nothing.\n",
    "        \"\"\"\n",
    "        if self.mab is None:\n",
    "            self._init(np.unique(decisions).shape[0])\n",
    "        self.mab.fit(decisions, rewards, contexts)\n",
    "    \n",
    "    def recommend(self, contexts: Union[None, List[List[Num]], np.ndarray, pd.Series, pd.DataFrame] = None,\n",
    "                  excluded_arms: List[List[Arm]] = None, return_scores: bool = False, apply_sigmoid: bool = True) \\\n",
    "            -> Union[Union[List[Arm], Tuple[List[Arm], List[Num]],\n",
    "                     Union[List[List[Arm]], Tuple[List[List[Arm]], List[List[Num]]]]]]:\n",
    "        self._validate_mab(is_fit=True)\n",
    "        self._validate_get_rec(contexts, excluded_arms)\n",
    "\n",
    "        print('oi1')\n",
    "        start_time = time.time()\n",
    "        # Get predicted expectations\n",
    "        num_contexts = len(contexts) if contexts is not None else 1\n",
    "        if num_contexts == 1:\n",
    "            expectations = [self.mab.predict_expectations(contexts)]\n",
    "        else:\n",
    "            expectations = self.mab.predict_expectations(contexts)\n",
    "        print(f'predict_expectations demorou {time.time() - start_time} segundos')\n",
    "        print('oi2')\n",
    "\n",
    "        if apply_sigmoid:\n",
    "            expectations = expit(expectations)\n",
    "\n",
    "        # Create an exclusion mask, where exclusion_mask[context_ind][arm_ind] denotes if the arm with the\n",
    "        # index arm_ind was excluded for context with the index context_ind.\n",
    "        # The value will be True if it is excluded and those arms will not be returned as part of the results.\n",
    "        print('criando matriz de exclusão de arms')\n",
    "        arm_to_index = {arm: arm_ind for arm_ind, arm in enumerate(self.mab.arms)}\n",
    "        exclude_mask = np.zeros((num_contexts, len(self.mab.arms)), dtype=bool)\n",
    "        if excluded_arms is not None:\n",
    "            for context_ind, excluded in tqdm(enumerate(excluded_arms), total=len(excluded_arms)):\n",
    "                exclude_mask[context_ind][[arm_to_index[arm] for arm in excluded if arm in arm_to_index]] = True\n",
    "\n",
    "        # Set excluded item scores to -1, so they automatically get placed lower in best results\n",
    "        expectations[exclude_mask] = -1.\n",
    "\n",
    "        print('fazendo a ordenação top-K')\n",
    "        start_time = time.time()\n",
    "        # Get best `top_k` results by sorting the expectations\n",
    "        arm_inds = np.argpartition(-expectations, self.top_k - 1, axis=1)[:, :self.top_k]\n",
    "        arm_inds = arm_inds[np.arange(arm_inds.shape[0]).reshape(-1, 1), np.argsort(-expectations[np.arange(expectations.shape[0]).reshape(-1, 1), arm_inds], axis=1)]\n",
    "        print(f'demorou {time.time() - start_time} segundos')\n",
    "        \n",
    "\n",
    "        print('gerando lista de recomendações')\n",
    "        start_time = time.time()\n",
    "        # Get the list of top_k recommended items and corresponding expectations for each context\n",
    "        recommendations = [[]] * num_contexts\n",
    "        scores = [[]] * num_contexts\n",
    "        for context_ind in range(num_contexts):\n",
    "            recommendations[context_ind] = [self.mab.arms[arm_ind] for arm_ind in arm_inds[context_ind]\n",
    "                                            if not exclude_mask[context_ind, arm_ind]]\n",
    "            if return_scores:\n",
    "                scores[context_ind] = [expectations[context_ind, arm_ind] for arm_ind in arm_inds[context_ind]\n",
    "                                       if not exclude_mask[context_ind, arm_ind]]\n",
    "        print(f'demorou {time.time() - start_time} segundos')\n",
    "        # Return recommendations and scores\n",
    "        if return_scores:\n",
    "            if num_contexts > 1:\n",
    "                return recommendations, scores\n",
    "            else:\n",
    "                return recommendations[0], scores[0]\n",
    "        else:\n",
    "            if num_contexts > 1:\n",
    "                return recommendations\n",
    "            else:\n",
    "                return recommendations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(test_size, train_initial_size, train_extra_increment_step_size, windows_sizes):\n",
    "    '''\n",
    "    - `test_size`: define o tamanho da partição de teste no train/test split inicial. Por exemplo, se for escolhido 0.1 (10%), a partição de teste terá 10% das interações e a partição de treino terá 90% das interações. O tamanho da partição de teste passará ainda por um filtro com o tamanho do treino inicial, definido no próximo parâmetro.\n",
    "    - `train_initial_size`: define o tamanho inicial que será usado para treino dos modelos. Esse tamanho é uma porcentagem da partição de treino, por exemplo, 0.5 (50%) quer dizer que o treino será feito inicialmente com 50% das interações separadas para treino. Vale ressaltar que essa porcentagem é relacionada apenas à partição de treino, então, se temos uma partição de treino de 0.9 (90%) e o “train_initial_size” é definido como 0.5 (50%), então, teremos 45% (0.9 * 0.5) das interações todas para o treino inicial. Com a base de treino separada com essa porcentagem inicial, a base de teste passara por um filtro, removendo todas as interações com itens ou usuários que nunca foram vistos nesse treino inicial.\n",
    "    - `train_extra_increment_step_size`: define a porcentagem do \"treinamento extra\" que será usado. No início a base de dados é separada em treino inicial (train_initial_size), \"treinamento extra\" e teste. O \"treinamento extra\", assim como o teste, passa por um filtro para remover interações com itens ou usuários que nunca foram vistos no treino inicial. Após o treino inicial, o \"treinamento extra\" é usado para treinar os modelos de embeddings e os modelos de bandit. O \"treinamento extra\" é incrementado a cada iteração, de acordo com o valor desse parâmetro. Por exemplo, se o `train_extra_increment_step_size` é 0.1 (10%), então, a cada iteração, 10% das interações são adicionadas ao treino, até que todo o \"treinamento extra\" seja usado.\n",
    "    - `windows_sizes`: tamanho das janelas de contextos que serão usadas para teste. Por exemplo, se for passado [3, 5, 7], as janelas de tamanho de 3, 5 e 7 serão usadas como contexto para treinar os modelos de MAB (gerando resultados diferentes para cada tamanho de janela).\n",
    "    '''\n",
    "    results = []\n",
    "    df_recs = pd.DataFrame(columns=['algorithm', 'interaction_number', 'user_id', 'item_id', 'recommendations'])\n",
    "    # df_train = pd.read_csv(train_data)\n",
    "    # df_test = pd.read_csv(test_data)\n",
    "\n",
    "    df_full = load_data()\n",
    "\n",
    "    df_full['user_id'] = pd.factorize(df_full['user_id'])[0]\n",
    "    df_full['item_id'] = pd.factorize(df_full['item_id'])[0]\n",
    "\n",
    "    num_users = df_full['user_id'].nunique()\n",
    "    num_items = df_full['item_id'].nunique()\n",
    "\n",
    "    split_index = int(len(df_full) * (1 - test_size))\n",
    "    df_train_full = df_full[:split_index]\n",
    "    df_test = df_full[split_index:]\n",
    "\n",
    "    initial_df_train = df_train_full[:int(len(df_train_full) * train_initial_size)]\n",
    "    extra_df_train = df_train_full[int(len(df_train_full) * train_initial_size):]\n",
    "    extra_df_train = extra_df_train[(extra_df_train['user_id'].isin(initial_df_train['user_id'])) & (extra_df_train['item_id'].isin(initial_df_train['item_id']))]\n",
    "    extra_df_train = extra_df_train.reset_index(drop=True)\n",
    "\n",
    "    df_test = df_test[(df_test['user_id'].isin(initial_df_train['user_id'])) & (df_test['item_id'].isin(initial_df_train['item_id']))]\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    df_test_for_evaluation = df_test[df_test['response'] == 1]\n",
    "    df_test_for_evaluation = df_test_for_evaluation.reset_index(drop=True)\n",
    "\n",
    "    print('Generating ALS embeddings')\n",
    "    ALS_model, _, ALS_item_embeddings, ALS_user_embeddings = train_embeddings_model(implicit.als.AlternatingLeastSquares, initial_df_train, num_users, num_items, generate_embeddings=True)\n",
    "\n",
    "    print('Generating BPR embeddings')\n",
    "    BPR_model, _, BPR_item_embeddings, BPR_user_embeddings = train_embeddings_model(implicit.bpr.BayesianPersonalizedRanking, initial_df_train, num_users, num_items, generate_embeddings=True)\n",
    "\n",
    "    '''\n",
    "    for window_size in windows_sizes:\n",
    "        print(f'Generating contexts for window size of {window_size} (contat items emb)')\n",
    "        df_full_new = pd.concat([initial_df_train, extra_df_train, df_test_for_evaluation])\n",
    "        als_contexts = create_contexts_list_items_concat(df_full_new, ALS_item_embeddings, window_size)\n",
    "        bpr_contexts = create_contexts_list_items_concat(df_full_new, BPR_item_embeddings, window_size)\n",
    "\n",
    "        initial_df_train[f'als_context_item_concat_{window_size}'] = als_contexts[:len(initial_df_train)]\n",
    "        initial_df_train[f'bpr_context_item_concat_{window_size}'] = bpr_contexts[:len(initial_df_train)]\n",
    "\n",
    "        extra_df_train[f'als_context_item_concat_{window_size}'] = als_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "        extra_df_train[f'bpr_context_item_concat_{window_size}'] = bpr_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "\n",
    "        df_test_for_evaluation[f'als_context_item_concat_{window_size}'] = als_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "        df_test_for_evaluation[f'bpr_context_item_concat_{window_size}'] = bpr_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "\n",
    "    print('Generating contexts for user embeddings')\n",
    "    df_full_new = pd.concat([initial_df_train, extra_df_train, df_test_for_evaluation])\n",
    "    als_contexts = create_contexts_list_user(df_full_new, ALS_user_embeddings)\n",
    "    bpr_contexts = create_contexts_list_user(df_full_new, BPR_user_embeddings)\n",
    "\n",
    "    initial_df_train['als_context_user'] = als_contexts[:len(initial_df_train)]\n",
    "    initial_df_train['bpr_context_user'] = bpr_contexts[:len(initial_df_train)]\n",
    "\n",
    "    extra_df_train['als_context_user'] = als_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "    extra_df_train['bpr_context_user'] = bpr_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "\n",
    "    df_test_for_evaluation['als_context_user'] = als_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "    df_test_for_evaluation['bpr_context_user'] = bpr_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "    '''\n",
    "    \n",
    "    print('Generating contexts for item mean embeddings')\n",
    "    df_full_new = pd.concat([initial_df_train, extra_df_train, df_test_for_evaluation])\n",
    "    als_contexts = create_contexts_list_items_mean(df_full_new, ALS_item_embeddings)\n",
    "    bpr_contexts = create_contexts_list_items_mean(df_full_new, BPR_item_embeddings)\n",
    "\n",
    "    initial_df_train['als_context_items_mean'] = als_contexts[:len(initial_df_train)]\n",
    "    initial_df_train['bpr_context_items_mean'] = bpr_contexts[:len(initial_df_train)]\n",
    "\n",
    "    extra_df_train['als_context_items_mean'] = als_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "    extra_df_train['bpr_context_items_mean'] = bpr_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "\n",
    "    df_test_for_evaluation['als_context_items_mean'] = als_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "    df_test_for_evaluation['bpr_context_items_mean'] = bpr_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "\n",
    "    algos_dict = {\n",
    "        # 'item_concat': {\n",
    "        #     'item_concat': True,\n",
    "        #     'item_mean': False,\n",
    "        #     'user': False\n",
    "        # },\n",
    "        'item_mean': {\n",
    "            'item_concat': False,\n",
    "            'item_mean': True,\n",
    "            'user': False\n",
    "        },\n",
    "        # 'user': {\n",
    "        #     'item_concat': False,\n",
    "        #     'item_mean': False,\n",
    "        #     'user': True\n",
    "        # },\n",
    "        # 'item_concat-item_mean': {\n",
    "        #     'item_concat': True,\n",
    "        #     'item_mean': True,\n",
    "        #     'user': False\n",
    "        # },\n",
    "        # 'item_concat-user': {\n",
    "        #     'item_concat': True,\n",
    "        #     'item_mean': False,\n",
    "        #     'user': True\n",
    "        # },\n",
    "        # 'item_mean-user': {\n",
    "        #     'item_concat': False,\n",
    "        #     'item_mean': True,\n",
    "        #     'user': True\n",
    "        # },\n",
    "        # 'all': {\n",
    "        #     'item_concat': True,\n",
    "        #     'item_mean': True,\n",
    "        #     'user': True\n",
    "        # }\n",
    "    }\n",
    "\n",
    "    for algo_name, _ in algos_dict.items():\n",
    "        algos_dict[algo_name]['results'] = []\n",
    "        algos_dict[algo_name]['df_recs'] = pd.DataFrame(columns=['algorithm', 'interaction_number', 'user_id', 'item_id', 'recommendations'])\n",
    "\n",
    "    def save_algo_result(algo_name, hits, hr, spent_time, df_recs_algo, current_extra_train_size, results):\n",
    "        df_recs_algo['algorithm'] = algo_name\n",
    "        df_recs_algo['train_size'] = current_extra_train_size\n",
    "        df_recs_new = pd.concat([df_recs, df_recs_algo])\n",
    "        results.append({'algorithm': algo_name, 'hits': hits, 'hr': hr, 'time': spent_time, 'train_size': current_extra_train_size})\n",
    "        return df_recs_new\n",
    "\n",
    "    current_extra_train_size = 0\n",
    "    while current_extra_train_size <= 1:\n",
    "        print(f\"Current extra train size: {current_extra_train_size}\")\n",
    "\n",
    "        current_df_train = pd.concat([initial_df_train, extra_df_train[:int(len(extra_df_train) * current_extra_train_size)]])\n",
    "        interactions_by_user = group_interactions_by_user(current_df_train)  # MUDANÇA AQUI\n",
    "\n",
    "        # -------------- ALS -----------------\n",
    "        print('Training ALS')\n",
    "        ALS_model, sparse_matrix = train_embeddings_model(implicit.als.AlternatingLeastSquares, current_df_train, num_users, num_items)\n",
    "\n",
    "        print('Testing ALS')\n",
    "        hits, hr, spent_time, df_recs_als = test_embeddings_model(ALS_model, sparse_matrix, df_test_for_evaluation)\n",
    "        df_recs = save_algo_result('ALS', hits, hr, spent_time, df_recs_als, current_extra_train_size, results)\n",
    "\n",
    "        # -------------- BPR -----------------\n",
    "        print('Training BPR')\n",
    "        BPR_model, sparse_matrix = train_embeddings_model(implicit.bpr.BayesianPersonalizedRanking, current_df_train, num_users, num_items)\n",
    "\n",
    "        print('Testing BPR')\n",
    "        hits, hr, spent_time, df_recs_bpr = test_embeddings_model(BPR_model, sparse_matrix, df_test_for_evaluation)\n",
    "        df_recs = save_algo_result('BPR', hits, hr, spent_time, df_recs_bpr, current_extra_train_size, results)\n",
    "        \n",
    "        for algo_name, algo_dict in algos_dict.items():\n",
    "            if algo_dict['item_concat']:\n",
    "                windows = windows_sizes\n",
    "            else:\n",
    "                windows = [None]\n",
    "            \n",
    "            for window_size in windows:\n",
    "                als_embeddings_cols = []\n",
    "                bpr_embeddings_cols = []\n",
    "                print_extra = f' - {algo_name}'\n",
    "                algo_name_extra = ''\n",
    "                if algo_dict['item_concat']:\n",
    "                    als_embeddings_cols.append(f'als_context_item_concat_{window_size}')\n",
    "                    bpr_embeddings_cols.append(f'bpr_context_item_concat_{window_size}')\n",
    "                    print_extra = f' - {algo_name} - {window_size}'\n",
    "                    algo_name_extra = f' - {window_size}'\n",
    "                if algo_dict['item_mean']:\n",
    "                    als_embeddings_cols.append('als_context_items_mean')\n",
    "                    bpr_embeddings_cols.append('bpr_context_items_mean')\n",
    "                if algo_dict['user']:\n",
    "                    als_embeddings_cols.append('als_context_user')\n",
    "                    bpr_embeddings_cols.append('bpr_context_user')\n",
    "                \n",
    "                # ------ LinUCB - ALS embeddings -------\n",
    "                print(f'Training LinUCB - ALS embeddings{print_extra}')\n",
    "                linUCB_model = BanditRecommenderArmEncoded(learning_policy=LearningPolicy.LinUCB(alpha=0.1), top_k=10)\n",
    "                start_time = time.time()\n",
    "                train_mab(linUCB_model, current_df_train, als_embeddings_cols)  # Mudança no treinamento dos MAB\n",
    "                print(f'Treinamento demorou {time.time() - start_time} segundos')\n",
    "\n",
    "                print(f'Testing LinUCB - ALS embeddings{print_extra}')\n",
    "                hits, hr, spent_time, df_recs_linUCB = test_non_incremental(linUCB_model, als_embeddings_cols, df_test_for_evaluation, interactions_by_user)\n",
    "                algo_dict['df_recs'] = save_algo_result(f'LinUCB - ALS embeddings{algo_name_extra}', hits, hr, spent_time, df_recs_linUCB, current_extra_train_size, algo_dict['results'])\n",
    "\n",
    "\n",
    "                # ------ LinUCB - BPR embeddings -------\n",
    "                print(f'Training LinUCB - BPR embeddings{print_extra}')\n",
    "                linUCB_model = BanditRecommenderArmEncoded(learning_policy=LearningPolicy.LinUCB(alpha=0.1), top_k=10)\n",
    "                train_mab(linUCB_model, current_df_train, bpr_embeddings_cols)\n",
    "\n",
    "                print(f'Testing LinUCB - BPR embeddings{print_extra}')\n",
    "                hits, hr, spent_time, df_recs_linUCB = test_non_incremental(linUCB_model, bpr_embeddings_cols, df_test_for_evaluation, interactions_by_user)\n",
    "                algo_dict['df_recs'] = save_algo_result(f'LinUCB - BPR embeddings{algo_name_extra}', hits, hr, spent_time, df_recs_linUCB, current_extra_train_size, algo_dict['results'])\n",
    "\n",
    "                # ------ LinGreedy - ALS embeddings -------\n",
    "                print(f'Training LinGreedy - ALS embeddings{print_extra}')\n",
    "                linGreedy_model = BanditRecommenderArmEncoded(learning_policy=LearningPolicy.LinGreedy(epsilon=0.01), top_k=10)\n",
    "                train_mab(linGreedy_model, current_df_train, als_embeddings_cols)\n",
    "\n",
    "                print(f'Testing LinGreedy - ALS embeddings{print_extra}')\n",
    "                hits, hr, spent_time, df_recs_linGreedy = test_non_incremental(linGreedy_model, als_embeddings_cols, df_test_for_evaluation, interactions_by_user)\n",
    "                algo_dict['df_recs'] = save_algo_result(f'LinGreedy - ALS embeddings{algo_name_extra}', hits, hr, spent_time, df_recs_linGreedy, current_extra_train_size, algo_dict['results'])\n",
    "\n",
    "\n",
    "                # ------ LinGreedy - BPR embeddings -------\n",
    "                print(f'Training LinGreedy - BPR embeddings{print_extra}')\n",
    "                linGreedy_model = BanditRecommenderArmEncoded(learning_policy=LearningPolicy.LinGreedy(epsilon=0.01), top_k=10)\n",
    "                train_mab(linGreedy_model, current_df_train, bpr_embeddings_cols)\n",
    "\n",
    "                print(f'Testing LinGreedy - BPR embeddings{print_extra}')\n",
    "                hits, hr, spent_time, df_recs_linGreedy = test_non_incremental(linGreedy_model, bpr_embeddings_cols, df_test_for_evaluation, interactions_by_user)\n",
    "                algo_dict['df_recs'] = save_algo_result(f'LinGreedy - BPR embeddings{algo_name_extra}', hits, hr, spent_time, df_recs_linGreedy, current_extra_train_size, algo_dict['results'])\n",
    "        \n",
    "        # Incrementando o tamanho do treino para próxima iteração\n",
    "        current_extra_train_size = round(current_extra_train_size + train_extra_increment_step_size, 2)\n",
    "    \n",
    "    save_path = f'results-v15/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    df_results_als_bpr = pd.DataFrame(results)\n",
    "    for algo_name, algo_dict in algos_dict.items():\n",
    "        df_results_final = pd.DataFrame(algo_dict['results'])\n",
    "        df_results_final = pd.concat([df_results_final, df_results_als_bpr])\n",
    "        df_results_final = df_results_final.astype({'hits': int, 'hr': float, 'time': float})\n",
    "        df_results_final['test_size'] = round(test_size, 2)\n",
    "        df_results_final['test_interactions'] = len(df_test_for_evaluation)\n",
    "\n",
    "        df_results_final.to_csv(f'{save_path}/results-{algo_name}.csv', index=False)\n",
    "\n",
    "        df_recs_final = pd.concat([df_recs, algo_dict['df_recs']])\n",
    "        df_recs_final.to_csv(f'{save_path}/recs-{algo_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ALS embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:36<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BPR embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 93.61it/s, train_auc=92.25%, skipped=0.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contexts for item mean embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461136/461136 [00:32<00:00, 14299.98it/s]\n",
      "100%|██████████| 461136/461136 [00:31<00:00, 14562.77it/s]\n",
      "/tmp/ipykernel_93077/1430151853.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_df_train['als_context_items_mean'] = als_contexts[:len(initial_df_train)]\n",
      "/tmp/ipykernel_93077/1430151853.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_df_train['bpr_context_items_mean'] = bpr_contexts[:len(initial_df_train)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current extra train size: 0\n",
      "Training ALS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:37<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:04<00:00, 790.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BPR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 86.81it/s, train_auc=92.24%, skipped=0.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:04<00:00, 812.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinUCB - ALS embeddings - item_mean\n",
      "arm_to_model demorou -0.4441554546356201\n",
      "reset_arm_to_status demorou -4.0531158447265625e-06\n",
      "paralel fit demorou -22.15251326560974\n",
      "_set_arms_as_trained acabou em -4.76837158203125e-07 segundos\n",
      "Treinamento demorou 27.821632623672485 segundos\n",
      "Testing LinUCB - ALS embeddings - item_mean\n",
      "entrou\n",
      "saiu\n",
      "oi1\n",
      "random values\n",
      "[0.22733602 0.31675834 0.79736546 ... 0.11546996 0.43684616 0.5604927 ]\n",
      "Gerando as predições\n",
      "Gerar as predições demorou 24.15371322631836 segundos\n",
      "predict_expectations demorou 24.154807090759277 segundos\n",
      "oi2\n",
      "criando matriz de exclusão de arms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 127313.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fazendo a ordenação top-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.5695433616638184 segundos\n",
      "gerando lista de recomendações\n",
      "demorou 0.024473190307617188 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 15580.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinUCB - BPR embeddings - item_mean\n",
      "arm_to_model demorou -0.40575742721557617\n",
      "reset_arm_to_status demorou -3.814697265625e-06\n",
      "paralel fit demorou -20.364905834197998\n",
      "_set_arms_as_trained acabou em -2.384185791015625e-07 segundos\n",
      "Testing LinUCB - BPR embeddings - item_mean\n",
      "entrou\n",
      "saiu\n",
      "oi1\n",
      "random values\n",
      "[0.22733602 0.31675834 0.79736546 ... 0.11546996 0.43684616 0.5604927 ]\n",
      "Gerando as predições\n",
      "Gerar as predições demorou 24.6965389251709 segundos\n",
      "predict_expectations demorou 24.697410583496094 segundos\n",
      "oi2\n",
      "criando matriz de exclusão de arms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 132687.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fazendo a ordenação top-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.582766056060791 segundos\n",
      "gerando lista de recomendações\n",
      "demorou 0.02153182029724121 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 15499.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinGreedy - ALS embeddings - item_mean\n",
      "arm_to_model demorou -0.35843563079833984\n",
      "reset_arm_to_status demorou -1.1920928955078125e-06\n",
      "paralel fit demorou -20.642829656600952\n",
      "_set_arms_as_trained acabou em -4.76837158203125e-07 segundos\n",
      "Testing LinGreedy - ALS embeddings - item_mean\n",
      "entrou\n",
      "saiu\n",
      "oi1\n",
      "random values\n",
      "[0.22733602 0.31675834 0.79736546 ... 0.11546996 0.43684616 0.5604927 ]\n",
      "Gerando as predições\n",
      "Gerar as predições demorou 3.3813955783843994 segundos\n",
      "predict_expectations demorou 3.40777325630188 segundos\n",
      "oi2\n",
      "criando matriz de exclusão de arms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 159505.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fazendo a ordenação top-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.553048849105835 segundos\n",
      "gerando lista de recomendações\n",
      "demorou 0.019666433334350586 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 15358.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinGreedy - BPR embeddings - item_mean\n",
      "arm_to_model demorou -0.3487551212310791\n",
      "reset_arm_to_status demorou -9.5367431640625e-07\n",
      "paralel fit demorou -21.007943868637085\n",
      "_set_arms_as_trained acabou em -2.384185791015625e-07 segundos\n",
      "Testing LinGreedy - BPR embeddings - item_mean\n",
      "entrou\n",
      "saiu\n",
      "oi1\n",
      "random values\n",
      "[0.22733602 0.31675834 0.79736546 ... 0.11546996 0.43684616 0.5604927 ]\n",
      "Gerando as predições\n",
      "Gerar as predições demorou 3.4279470443725586 segundos\n",
      "predict_expectations demorou 3.453890562057495 segundos\n",
      "oi2\n",
      "criando matriz de exclusão de arms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 162464.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fazendo a ordenação top-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.555213212966919 segundos\n",
      "gerando lista de recomendações\n",
      "demorou 0.02155470848083496 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 15516.58it/s]\n"
     ]
    }
   ],
   "source": [
    "test(test_size=0.1, train_initial_size=0.5, train_extra_increment_step_size=10, windows_sizes=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('results-v15/results-item_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.line(df_results, x=\"train_size\", y=\"hr\", color='algorithm', title='HR x Train size')\n",
    "#fig.show()\n",
    "#fig.write_html('results-v15/hr_x_train_size.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>hits</th>\n",
       "      <th>hr</th>\n",
       "      <th>time</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>test_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinUCB - ALS embeddings</td>\n",
       "      <td>22</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>26.198028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinUCB - BPR embeddings</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>26.753603</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinGreedy - ALS embeddings</td>\n",
       "      <td>114</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>5.408048</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinGreedy - BPR embeddings</td>\n",
       "      <td>56</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>5.459213</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALS</td>\n",
       "      <td>89</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>4.816372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPR</td>\n",
       "      <td>25</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>4.684150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    algorithm  hits        hr       time  train_size  \\\n",
       "0     LinUCB - ALS embeddings    22  0.005791  26.198028           0   \n",
       "1     LinUCB - BPR embeddings     3  0.000790  26.753603           0   \n",
       "2  LinGreedy - ALS embeddings   114  0.030008   5.408048           0   \n",
       "3  LinGreedy - BPR embeddings    56  0.014741   5.459213           0   \n",
       "4                         ALS    89  0.023427   4.816372           0   \n",
       "5                         BPR    25  0.006581   4.684150           0   \n",
       "\n",
       "   test_size  test_interactions  \n",
       "0        0.1               3799  \n",
       "1        0.1               3799  \n",
       "2        0.1               3799  \n",
       "3        0.1               3799  \n",
       "4        0.1               3799  \n",
       "5        0.1               3799  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_incremental(df_results):\n",
    "    new_df = df_results[(~df_results['algorithm'].str.contains('incremental') | df_results['algorithm'].str.contains('non-incremental'))]\n",
    "    new_df['algorithm'] = new_df['algorithm'].str.replace(' - non-incremental', '')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_in_upper_and_lower_bounds(df_results, algo_names):\n",
    "    train_sizes = sorted(df_results['train_size'].unique().tolist())\n",
    "    min_train_size = train_sizes[0]\n",
    "    max_train_size = train_sizes[-1]\n",
    "    qnt_train_sizes = len(train_sizes)\n",
    "\n",
    "    for algo_name in algo_names:\n",
    "        algo_row_lower = df_results[(df_results['algorithm'] == algo_name) & (df_results['train_size'] == min_train_size)]\n",
    "        df_lower = pd.DataFrame({\n",
    "            'algorithm': [f'{algo_name} lower'] * qnt_train_sizes,\n",
    "            'hits': [algo_row_lower['hits'].values[0]] * qnt_train_sizes,\n",
    "            'hr': [algo_row_lower['hr'].values[0]] * qnt_train_sizes,\n",
    "            'time': [algo_row_lower['time'].values[0]] * qnt_train_sizes,\n",
    "            'train_size': train_sizes,\n",
    "            'test_size': [algo_row_lower['test_size'].values[0]] * qnt_train_sizes,\n",
    "            'test_interactions': [algo_row_lower['test_interactions'].values[0]] * qnt_train_sizes\n",
    "        })\n",
    "        df_results = pd.concat([df_results, df_lower])\n",
    "\n",
    "        algo_row_upper = df_results[(df_results['algorithm'] == algo_name) & (df_results['train_size'] == max_train_size)]\n",
    "        df_upper = pd.DataFrame({\n",
    "            'algorithm': [f'{algo_name} upper'] * qnt_train_sizes,\n",
    "            'hits': [algo_row_upper['hits'].values[0]] * qnt_train_sizes,\n",
    "            'hr': [algo_row_upper['hr'].values[0]] * qnt_train_sizes,\n",
    "            'time': [algo_row_upper['time'].values[0]] * qnt_train_sizes,\n",
    "            'train_size': train_sizes,\n",
    "            'test_size': [algo_row_upper['test_size'].values[0]] * qnt_train_sizes,\n",
    "            'test_interactions': [algo_row_upper['test_interactions'].values[0]] * qnt_train_sizes\n",
    "        })\n",
    "        df_results = pd.concat([df_results, df_upper])\n",
    "\n",
    "        df_results = df_results[df_results['algorithm'] != algo_name]\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_results(df_results, save_root):\n",
    "    df_results = remove_incremental(df_results)\n",
    "    df_results = transform_in_upper_and_lower_bounds(df_results, ['ALS', 'BPR'])\n",
    "\n",
    "    algos_configs = {\n",
    "        'ALS upper': {'color': 'blue', 'dash': 'dash'},\n",
    "        'ALS lower': {'color': 'blue', 'dash': 'dash'},\n",
    "        'BPR upper': {'color': 'red', 'dash': 'dash'},\n",
    "        'BPR lower': {'color': 'red', 'dash': 'dash'},\n",
    "        'LinUCB - ALS embeddings': {'color': 'green', 'dash': 'solid'},\n",
    "        'LinUCB - BPR embeddings': {'color': 'purple', 'dash': 'solid'},\n",
    "        'LinGreedy - ALS embeddings': {'color': 'orange', 'dash': 'solid'},\n",
    "        'LinGreedy - BPR embeddings': {'color': 'pink', 'dash': 'solid'}\n",
    "    }\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for algo_name, config in algos_configs.items():\n",
    "        df_algo = df_results[df_results['algorithm'] == algo_name]\n",
    "        fig.add_trace(go.Scatter(x=df_algo['train_size'], y=df_algo['hr'], mode='lines', name=algo_name, line=dict(color=config['color'], dash=config['dash'])))\n",
    "    \n",
    "    fig.update_layout(title='HR x Train size', xaxis_title='Train size', yaxis_title='HR')\n",
    "    # fig.show()\n",
    "\n",
    "    fig.write_html(f'{save_root}/hr_x_train_size.html')\n",
    "    # fig.write_image(f'{save_root}/hr_x_train_size.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>hits</th>\n",
       "      <th>hr</th>\n",
       "      <th>time</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>test_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinUCB - ALS embeddings</td>\n",
       "      <td>16</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>25.781378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinUCB - BPR embeddings</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>25.469453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinGreedy - ALS embeddings</td>\n",
       "      <td>86</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>5.340262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinGreedy - BPR embeddings</td>\n",
       "      <td>46</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>5.343321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinUCB - ALS embeddings</td>\n",
       "      <td>16</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>25.531457</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>BPR</td>\n",
       "      <td>42</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>4.304660</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ALS</td>\n",
       "      <td>97</td>\n",
       "      <td>0.025533</td>\n",
       "      <td>4.499696</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>BPR</td>\n",
       "      <td>42</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>4.294375</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ALS</td>\n",
       "      <td>96</td>\n",
       "      <td>0.025270</td>\n",
       "      <td>4.567436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BPR</td>\n",
       "      <td>41</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>4.318658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     algorithm  hits        hr       time  train_size  \\\n",
       "0      LinUCB - ALS embeddings    16  0.004212  25.781378         0.0   \n",
       "1      LinUCB - BPR embeddings     4  0.001053  25.469453         0.0   \n",
       "2   LinGreedy - ALS embeddings    86  0.022638   5.340262         0.0   \n",
       "3   LinGreedy - BPR embeddings    46  0.012108   5.343321         0.0   \n",
       "4      LinUCB - ALS embeddings    16  0.004212  25.531457         0.1   \n",
       "..                         ...   ...       ...        ...         ...   \n",
       "61                         BPR    42  0.011056   4.304660         0.8   \n",
       "62                         ALS    97  0.025533   4.499696         0.9   \n",
       "63                         BPR    42  0.011056   4.294375         0.9   \n",
       "64                         ALS    96  0.025270   4.567436         1.0   \n",
       "65                         BPR    41  0.010792   4.318658         1.0   \n",
       "\n",
       "    test_size  test_interactions  \n",
       "0         0.1               3799  \n",
       "1         0.1               3799  \n",
       "2         0.1               3799  \n",
       "3         0.1               3799  \n",
       "4         0.1               3799  \n",
       "..        ...                ...  \n",
       "61        0.1               3799  \n",
       "62        0.1               3799  \n",
       "63        0.1               3799  \n",
       "64        0.1               3799  \n",
       "65        0.1               3799  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(df_results)\n",
    "\n",
    "plot_results(df_results, 'results-v15')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLRS-rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
