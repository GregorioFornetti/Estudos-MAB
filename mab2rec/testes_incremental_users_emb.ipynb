{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id\n",
       "0         1        0\n",
       "1         2        0\n",
       "2         1        4\n",
       "3         1        1\n",
       "4         3        4\n",
       "5         2        1\n",
       "6         4        0\n",
       "7         5        4\n",
       "8         2        4\n",
       "9         4        4\n",
       "10        4        2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_example = pd.DataFrame([\n",
    "    {\n",
    "        \"user_id\": 1,\n",
    "        \"item_id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 2,\n",
    "        \"item_id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 1,\n",
    "        \"item_id\": 4\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 1,\n",
    "        \"item_id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 3,\n",
    "        \"item_id\": 4\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 2,\n",
    "        \"item_id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 4,\n",
    "        \"item_id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 5,\n",
    "        \"item_id\": 4\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 2,\n",
    "        \"item_id\": 4\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 4,\n",
    "        \"item_id\": 4\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 4,\n",
    "        \"item_id\": 2\n",
    "    }\n",
    "])\n",
    "interactions_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_embeddings = [\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [2, 2, 2, 2, 2],\n",
    "    [3, 3, 3, 3, 3],\n",
    "    [4, 4, 4, 4, 4],\n",
    "    [5, 5, 5, 5, 5]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_embeddings = np.array(users_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, 1, 1]),\n",
       " array([2, 2, 2, 2, 2]),\n",
       " array([1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1]),\n",
       " array([3, 3, 3, 3, 3]),\n",
       " array([2, 2, 2, 2, 2]),\n",
       " array([4, 4, 4, 4, 4]),\n",
       " array([5, 5, 5, 5, 5]),\n",
       " array([2, 2, 2, 2, 2]),\n",
       " array([4, 4, 4, 4, 4]),\n",
       " array([4, 4, 4, 4, 4])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = []\n",
    "\n",
    "for i, row in interactions_example.iterrows():\n",
    "    user_id = row[\"user_id\"]\n",
    "    item_id = row[\"item_id\"]\n",
    "    \n",
    "    contexts.append(users_embeddings[user_id])\n",
    "\n",
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[4, 4, 4, 4, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 4, 4, 4, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 4, 4, 4, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id          context\n",
       "0         1        0  [1, 1, 1, 1, 1]\n",
       "1         2        0  [2, 2, 2, 2, 2]\n",
       "2         1        4  [1, 1, 1, 1, 1]\n",
       "3         1        1  [1, 1, 1, 1, 1]\n",
       "4         3        4  [3, 3, 3, 3, 3]\n",
       "5         2        1  [2, 2, 2, 2, 2]\n",
       "6         4        0  [4, 4, 4, 4, 4]\n",
       "7         5        4  [5, 5, 5, 5, 5]\n",
       "8         2        4  [2, 2, 2, 2, 2]\n",
       "9         4        4  [4, 4, 4, 4, 4]\n",
       "10        4        2  [4, 4, 4, 4, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_example['context'] = contexts\n",
    "interactions_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando os modelos MAB usando embeddings de itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "import plotly.express as px\n",
    "import time\n",
    "import os\n",
    "import implicit\n",
    "from mab2rec import BanditRecommender, LearningPolicy\n",
    "\n",
    "train_data = \"../data/ml100k/data_train.csv\"\n",
    "test_data = \"../data/ml100k/data_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_embeddings_model(Model, df, num_users, num_items, generate_embeddings=False):\n",
    "    sparse_matrix = csr_matrix((df['response'], (df['user_id'], df['item_id'])), shape=(num_users, num_items))\n",
    "\n",
    "    model = Model(factors=FACTORS, random_state=1, num_threads=1)\n",
    "    model.fit(sparse_matrix)\n",
    "\n",
    "    if not generate_embeddings:\n",
    "        return model, sparse_matrix\n",
    "    \n",
    "    # # Não precisamos mais do código abaixo, ele funcina para embeddings de usuário, não de itens\n",
    "    # user_features_list = []\n",
    "\n",
    "    # for user_id in df['user_id'].unique():\n",
    "    #    user_factors = model.user_factors[user_id][:FACTORS]  # O BPR coloca 1 no final dos vetores latentes ?\n",
    "    #    user_features_list.append([user_id] + list(user_factors))\n",
    "\n",
    "    # df_user_features = pd.DataFrame(user_features_list, columns=['user_id'] + [f'u{i}' for i in range(FACTORS)])\n",
    "\n",
    "    return model, sparse_matrix, model.user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_embeddings_model(model, sparse_matrix, df_test):\n",
    "    all_recs = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    hits = 0\n",
    "    for _, interaction in df_test.iterrows():\n",
    "        ids_recs, _ = model.recommend(userid=interaction['user_id'], user_items=sparse_matrix[interaction['user_id']], N=10)\n",
    "        if interaction['item_id'] in ids_recs:\n",
    "            hits += 1\n",
    "        all_recs.append(ids_recs.tolist())\n",
    "    \n",
    "    recs_df = pd.DataFrame({\n",
    "        'interaction_number': [i for i in range(len(df_test))],\n",
    "        'user_id': df_test['user_id'],\n",
    "        'item_id': df_test['item_id'],\n",
    "        'recommendations': all_recs\n",
    "    })\n",
    "    \n",
    "    return hits, hits/len(df_test), time.time() - start_time, recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_mab(mab_algo, df_train_with_contexts, context_col):\n",
    "    contexts = np.array(df_train_with_contexts[context_col].tolist())\n",
    "    mab_algo.fit(\n",
    "        decisions=df_train_with_contexts['item_id'],\n",
    "        rewards=df_train_with_contexts['response'],\n",
    "        contexts=contexts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_non_incremental(mab_algo, contexts_col, df_test, interactions_by_user):\n",
    "    start_time = time.time()\n",
    "    hits = 0\n",
    "\n",
    "    # contexts = df_test.merge(user_features, how='left', on='user_id').drop(columns=['user_id', 'item_id', 'response']).values\n",
    "    contexts = np.array(df_test[contexts_col].tolist())\n",
    "    filters = df_test.merge(interactions_by_user, how='left', on='user_id').drop(columns=['user_id', 'item_id', 'response', 'als_context', 'bpr_context']).values.squeeze(axis=1) \n",
    "\n",
    "    recomendations = mab_algo.recommend(contexts, filters)\n",
    "\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    hits = 0\n",
    "    for i, interaction in df_test.iterrows():\n",
    "        if interaction['item_id'] in recomendations[i]:\n",
    "            hits += 1\n",
    "    \n",
    "    recs_df = pd.DataFrame({\n",
    "        'interaction_number': [i for i in range(len(df_test))],\n",
    "        'user_id': df_test['user_id'],\n",
    "        'item_id': df_test['item_id'],\n",
    "        'recommendations': recomendations\n",
    "    })\n",
    "\n",
    "    return hits, hits/len(df_test), time.time() - start_time, recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_interactions_by_user(interactions_df):\n",
    "    interactions_by_user = interactions_df\\\n",
    "                        .groupby('user_id')[['item_id']]\\\n",
    "                        .apply(lambda df_user: df_user['item_id'].tolist())\\\n",
    "                        .reset_index(name='interactions')\n",
    "    interactions_by_user = interactions_by_user.reset_index(drop=True)\n",
    "    return interactions_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_list(interactions_df, users_embeddings):\n",
    "    contexts = []\n",
    "\n",
    "    for _, row in interactions_df.iterrows():\n",
    "        user_id = row[\"user_id\"]\n",
    "        contexts.append(users_embeddings[user_id])\n",
    "\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(test_size, train_initial_size, train_extra_increment_step_size):\n",
    "    '''\n",
    "    - `test_size`: define o tamanho da partição de teste no train/test split inicial. Por exemplo, se for escolhido 0.1 (10%), a partição de teste terá 10% das interações e a partição de treino terá 90% das interações. O tamanho da partição de teste passará ainda por um filtro com o tamanho do treino inicial, definido no próximo parâmetro.\n",
    "    - `train_initial_size`: define o tamanho inicial que será usado para treino dos modelos. Esse tamanho é uma porcentagem da partição de treino, por exemplo, 0.5 (50%) quer dizer que o treino será feito inicialmente com 50% das interações separadas para treino. Vale ressaltar que essa porcentagem é relacionada apenas à partição de treino, então, se temos uma partição de treino de 0.9 (90%) e o “train_initial_size” é definido como 0.5 (50%), então, teremos 45% (0.9 * 0.5) das interações todas para o treino inicial. Com a base de treino separada com essa porcentagem inicial, a base de teste passara por um filtro, removendo todas as interações com itens ou usuários que nunca foram vistos nesse treino inicial.\n",
    "    - `train_extra_increment_step_size`: define a porcentagem do \"treinamento extra\" que será usado. No início a base de dados é separada em treino inicial (train_initial_size), \"treinamento extra\" e teste. O \"treinamento extra\", assim como o teste, passa por um filtro para remover interações com itens ou usuários que nunca foram vistos no treino inicial. Após o treino inicial, o \"treinamento extra\" é usado para treinar os modelos de embeddings e os modelos de bandit. O \"treinamento extra\" é incrementado a cada iteração, de acordo com o valor desse parâmetro. Por exemplo, se o `train_extra_increment_step_size` é 0.1 (10%), então, a cada iteração, 10% das interações são adicionadas ao treino, até que todo o \"treinamento extra\" seja usado.\n",
    "    '''\n",
    "    results = []\n",
    "    df_recs = pd.DataFrame(columns=['algorithm', 'interaction_number', 'user_id', 'item_id', 'recommendations'])\n",
    "    df_train = pd.read_csv(train_data)\n",
    "    df_test = pd.read_csv(test_data)\n",
    "\n",
    "    df_full = pd.concat([df_train, df_test])\n",
    "\n",
    "    df_full['user_id'] = LabelEncoder().fit_transform(df_full['user_id'])\n",
    "    df_full['item_id'] = LabelEncoder().fit_transform(df_full['item_id'])\n",
    "\n",
    "    num_users = df_full['user_id'].nunique()\n",
    "    num_items = df_full['item_id'].nunique()\n",
    "\n",
    "    split_index = int(len(df_full) * (1 - test_size))\n",
    "    df_train_full = df_full[:split_index]\n",
    "    df_test = df_full[split_index:]\n",
    "\n",
    "    initial_df_train = df_train_full[:int(len(df_train_full) * train_initial_size)]\n",
    "    extra_df_train = df_train_full[int(len(df_train_full) * train_initial_size):]\n",
    "    extra_df_train = extra_df_train[(extra_df_train['user_id'].isin(initial_df_train['user_id'])) & (extra_df_train['item_id'].isin(initial_df_train['item_id']))]\n",
    "    extra_df_train = extra_df_train.reset_index(drop=True)\n",
    "\n",
    "    df_test = df_test[(df_test['user_id'].isin(initial_df_train['user_id'])) & (df_test['item_id'].isin(initial_df_train['item_id']))]\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    df_test_for_evaluation = df_test[df_test['response'] == 1]\n",
    "    df_test_for_evaluation = df_test_for_evaluation.reset_index(drop=True)\n",
    "\n",
    "    print('Generating ALS embeddings')\n",
    "    ALS_model, _, ALS_user_embeddings = train_embeddings_model(implicit.als.AlternatingLeastSquares, initial_df_train, num_users, num_items, generate_embeddings=True)\n",
    "\n",
    "    print('Generating BPR embeddings')\n",
    "    BPR_model, _, BPR_user_embeddings = train_embeddings_model(implicit.bpr.BayesianPersonalizedRanking, initial_df_train, num_users, num_items, generate_embeddings=True)\n",
    "\n",
    "    # MUDANCAS AQUI\n",
    "    df_full_new = pd.concat([initial_df_train, extra_df_train, df_test_for_evaluation])\n",
    "    als_contexts = create_contexts_list(df_full_new, ALS_user_embeddings)\n",
    "    bpr_contexts = create_contexts_list(df_full_new, BPR_user_embeddings)\n",
    "\n",
    "    initial_df_train['als_context'] = als_contexts[:len(initial_df_train)]\n",
    "    initial_df_train['bpr_context'] = bpr_contexts[:len(initial_df_train)]\n",
    "\n",
    "    extra_df_train['als_context'] = als_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "    extra_df_train['bpr_context'] = bpr_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "\n",
    "    df_test_for_evaluation['als_context'] = als_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "    df_test_for_evaluation['bpr_context'] = bpr_contexts[len(initial_df_train) + len(extra_df_train):]\n",
    "    # FIM DAS MUDANÇAS\n",
    "\n",
    "    def save_algo_result(algo_name, hits, hr, spent_time, df_recs_algo, current_extra_train_size):\n",
    "        df_recs_algo['algorithm'] = algo_name\n",
    "        df_recs_algo['train_size'] = current_extra_train_size\n",
    "        df_recs_new = pd.concat([df_recs, df_recs_algo])\n",
    "        results.append({'algorithm': algo_name, 'hits': hits, 'hr': hr, 'time': spent_time, 'train_size': current_extra_train_size})\n",
    "        return df_recs_new\n",
    "\n",
    "    current_extra_train_size = 0\n",
    "    while current_extra_train_size <= 1:\n",
    "        print(f\"Current extra train size: {current_extra_train_size}\")\n",
    "\n",
    "        current_df_train = pd.concat([initial_df_train, extra_df_train[:int(len(extra_df_train) * current_extra_train_size)]])\n",
    "        interactions_by_user = group_interactions_by_user(current_df_train)  # MUDANÇA AQUI\n",
    "\n",
    "        # -------------- ALS -----------------\n",
    "        print('Training ALS')\n",
    "        ALS_model, sparse_matrix = train_embeddings_model(implicit.als.AlternatingLeastSquares, current_df_train, num_users, num_items)\n",
    "\n",
    "        print('Testing ALS')\n",
    "        hits, hr, spent_time, df_recs_als = test_embeddings_model(ALS_model, sparse_matrix, df_test_for_evaluation)\n",
    "        df_recs = save_algo_result('ALS', hits, hr, spent_time, df_recs_als, current_extra_train_size)\n",
    "\n",
    "        # -------------- BPR -----------------\n",
    "        print('Training BPR')\n",
    "        BPR_model, sparse_matrix = train_embeddings_model(implicit.bpr.BayesianPersonalizedRanking, current_df_train, num_users, num_items)\n",
    "\n",
    "        print('Testing BPR')\n",
    "        hits, hr, spent_time, df_recs_bpr = test_embeddings_model(BPR_model, sparse_matrix, df_test_for_evaluation)\n",
    "        df_recs = save_algo_result('BPR', hits, hr, spent_time, df_recs_bpr, current_extra_train_size)\n",
    "\n",
    "        # ------ LinUCB - ALS embeddings -------\n",
    "        print('Training LinUCB - ALS embeddings')\n",
    "        linUCB_model = BanditRecommender(learning_policy=LearningPolicy.LinUCB(alpha=0.1), top_k=10)\n",
    "        train_mab(linUCB_model, current_df_train, 'als_context')  # Mudança no treinamento dos MAB\n",
    "\n",
    "        print('Testing LinUCB - ALS embeddings')\n",
    "        hits, hr, spent_time, df_recs_linUCB = test_non_incremental(linUCB_model, 'als_context', df_test_for_evaluation, interactions_by_user)\n",
    "        df_recs = save_algo_result('LinUCB - ALS embeddings', hits, hr, spent_time, df_recs_linUCB, current_extra_train_size)\n",
    "\n",
    "\n",
    "        # ------ LinUCB - BPR embeddings -------\n",
    "        print('Training LinUCB - BPR embeddings')\n",
    "        linUCB_model = BanditRecommender(learning_policy=LearningPolicy.LinUCB(alpha=0.1), top_k=10)\n",
    "        train_mab(linUCB_model, current_df_train, 'bpr_context')\n",
    "\n",
    "        print('Testing LinUCB - BPR embeddings')\n",
    "        hits, hr, spent_time, df_recs_linUCB = test_non_incremental(linUCB_model, 'bpr_context', df_test_for_evaluation, interactions_by_user)\n",
    "        df_recs = save_algo_result('LinUCB - BPR embeddings', hits, hr, spent_time, df_recs_linUCB, current_extra_train_size)\n",
    "\n",
    "        # ------ LinGreedy - ALS embeddings -------\n",
    "        print('Training LinGreedy - ALS embeddings')\n",
    "        linGreedy_model = BanditRecommender(learning_policy=LearningPolicy.LinGreedy(epsilon=0.01), top_k=10)\n",
    "        train_mab(linGreedy_model, current_df_train, 'als_context')\n",
    "\n",
    "        print('Testing LinGreedy - ALS embeddings')\n",
    "        hits, hr, spent_time, df_recs_linGreedy = test_non_incremental(linGreedy_model, 'als_context', df_test_for_evaluation, interactions_by_user)\n",
    "        df_recs = save_algo_result('LinGreedy - ALS embeddings', hits, hr, spent_time, df_recs_linGreedy, current_extra_train_size)\n",
    "\n",
    "\n",
    "        # ------ LinGreedy - BPR embeddings -------\n",
    "        print('Training LinGreedy - BPR embeddings')\n",
    "        linGreedy_model = BanditRecommender(learning_policy=LearningPolicy.LinGreedy(epsilon=0.01), top_k=10)\n",
    "        train_mab(linGreedy_model, current_df_train, 'bpr_context')\n",
    "\n",
    "        print('Testing LinGreedy - BPR embeddings')\n",
    "        hits, hr, spent_time, df_recs_linGreedy = test_non_incremental(linGreedy_model, 'bpr_context', df_test_for_evaluation, interactions_by_user)\n",
    "        df_recs = save_algo_result('LinGreedy - BPR embeddings', hits, hr, spent_time, df_recs_linGreedy, current_extra_train_size)\n",
    "        \n",
    "        # Incrementando o tamanho do treino para próxima iteração\n",
    "        current_extra_train_size = round(current_extra_train_size + train_extra_increment_step_size, 2)\n",
    "    \n",
    "    save_path = f'results-v8/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.astype({'hits': int, 'hr': float, 'time': float})\n",
    "    df_results['test_size'] = round(test_size, 2)\n",
    "    df_results['test_interactions'] = len(df_test_for_evaluation)\n",
    "\n",
    "    df_results.to_csv(f'{save_path}/results.csv', index=False)\n",
    "    df_recs.to_csv(f'{save_path}/recs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ALS embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f04269adeca43b984a68bfab4c1820e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BPR embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887457e5285e4e538ebd5f22d513d9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current extra train size: 0\n",
      "Training ALS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregf\\AppData\\Local\\Temp\\ipykernel_15216\\3127836564.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_df_train['als_context'] = als_contexts[:len(initial_df_train)]\n",
      "C:\\Users\\gregf\\AppData\\Local\\Temp\\ipykernel_15216\\3127836564.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_df_train['bpr_context'] = bpr_contexts[:len(initial_df_train)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804d4079953f400681a0ae145d45deb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1ca15c942d464bae902049707bfe51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.1\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55931a79557a4ab58a23b7b7f9aeaa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497c4c665ba64e90bef1844d81ac4c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.2\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f84a980c47d468ab1a385cb9070525a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cfc7b06842415faa105dc378f32e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.3\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568dc8fa2e314b89a3aee4d58ba7b3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903d709e2d8d4796ac2321aba45bf590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.4\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dd39c746024ff1a5672f1dc3e7bfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af805b49bb3e42e989c391ca19e7d0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.5\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69f85b3700a42b882359953b70b65e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3180b40be6455788ccee7f39087ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.6\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f0f424e66343d29a9e3a5d783c2ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f6fecbe5334edea28b5aa43e17efa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.7\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12816957a320483b82b4989130cce517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa0b107fed449059ff4d19cc58aa6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n",
      "Testing LinGreedy - ALS embeddings\n",
      "Training LinGreedy - BPR embeddings\n",
      "Testing LinGreedy - BPR embeddings\n",
      "Current extra train size: 0.8\n",
      "Training ALS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0d4042c050473a89feb6088f42c40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ALS\n",
      "Training BPR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ee1a1c0c154185aa6a82755e568ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BPR\n",
      "Training LinUCB - ALS embeddings\n",
      "Testing LinUCB - ALS embeddings\n",
      "Training LinUCB - BPR embeddings\n",
      "Testing LinUCB - BPR embeddings\n",
      "Training LinGreedy - ALS embeddings\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_initial_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_extra_increment_step_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 107\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(test_size, train_initial_size, train_extra_increment_step_size)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining LinGreedy - ALS embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m linGreedy_model \u001b[38;5;241m=\u001b[39m BanditRecommender(learning_policy\u001b[38;5;241m=\u001b[39mLearningPolicy\u001b[38;5;241m.\u001b[39mLinGreedy(epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[43mtrain_mab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinGreedy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_df_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mals_context\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting LinGreedy - ALS embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    110\u001b[0m hits, hr, spent_time, df_recs_linGreedy \u001b[38;5;241m=\u001b[39m test_non_incremental(linGreedy_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mals_context\u001b[39m\u001b[38;5;124m'\u001b[39m, df_test_for_evaluation, interactions_by_user)\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mtrain_mab\u001b[1;34m(mab_algo, df_train_with_contexts, context_col)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_mab\u001b[39m(mab_algo, df_train_with_contexts, context_col):\n\u001b[0;32m      2\u001b[0m     contexts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_train_with_contexts[context_col]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmab_algo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_with_contexts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrewards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_with_contexts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\mab2rec\\rec.py:219\u001b[0m, in \u001b[0;36mBanditRecommender.fit\u001b[1;34m(self, decisions, rewards, contexts)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(np\u001b[38;5;241m.\u001b[39munique(decisions)\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecisions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\mabwiser\\mab.py:1112\u001b[0m, in \u001b[0;36mMAB.fit\u001b[1;34m(self, decisions, rewards, contexts)\u001b[0m\n\u001b[0;32m   1109\u001b[0m contexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__convert_context(contexts, decisions)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Call the fit method\u001b[39;00m\n\u001b[1;32m-> 1112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_imp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecisions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# Turn initial to true\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initial_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\mabwiser\\linear.py:162\u001b[0m, in \u001b[0;36m_Linear.fit\u001b[1;34m(self, decisions, rewards, contexts)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_arm_to_status()\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Perform parallel fit\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecisions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Update trained arms\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_arms_as_trained(decisions\u001b[38;5;241m=\u001b[39mdecisions, is_partial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\mabwiser\\base_mab.py:215\u001b[0m, in \u001b[0;36mBaseMAB._parallel_fit\u001b[1;34m(self, decisions, rewards, contexts)\u001b[0m\n\u001b[0;32m    212\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_effective_jobs(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marms), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Perform parallel fit\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_arm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m                      \u001b[49m\u001b[43marm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecisions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\gregf\\anaconda3\\envs\\RLRS-rllib\\lib\\site-packages\\mabwiser\\linear.py:211\u001b[0m, in \u001b[0;36m_Linear._fit_arm\u001b[1;34m(self, arm, decisions, rewards, contexts)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lr\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Fit the regression\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcontexts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    212\u001b[0m y \u001b[38;5;241m=\u001b[39m rewards[indices]\n\u001b[0;32m    213\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(test_size=0.1, train_initial_size=0.5, train_extra_increment_step_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('results-v8/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_incremental(df_results):\n",
    "    new_df = df_results[(~df_results['algorithm'].str.contains('incremental') | df_results['algorithm'].str.contains('non-incremental'))]\n",
    "    new_df['algorithm'] = new_df['algorithm'].str.replace(' - non-incremental', '')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_in_upper_and_lower_bounds(df_results, algo_names):\n",
    "    train_sizes = sorted(df_results['train_size'].unique().tolist())\n",
    "    min_train_size = train_sizes[0]\n",
    "    max_train_size = train_sizes[-1]\n",
    "    qnt_train_sizes = len(train_sizes)\n",
    "\n",
    "    for algo_name in algo_names:\n",
    "        algo_row_lower = df_results[(df_results['algorithm'] == algo_name) & (df_results['train_size'] == min_train_size)]\n",
    "        df_lower = pd.DataFrame({\n",
    "            'algorithm': [f'{algo_name} lower'] * qnt_train_sizes,\n",
    "            'hits': [algo_row_lower['hits'].values[0]] * qnt_train_sizes,\n",
    "            'hr': [algo_row_lower['hr'].values[0]] * qnt_train_sizes,\n",
    "            'time': [algo_row_lower['time'].values[0]] * qnt_train_sizes,\n",
    "            'train_size': train_sizes,\n",
    "            'test_size': [algo_row_lower['test_size'].values[0]] * qnt_train_sizes,\n",
    "            'test_interactions': [algo_row_lower['test_interactions'].values[0]] * qnt_train_sizes\n",
    "        })\n",
    "        df_results = pd.concat([df_results, df_lower])\n",
    "\n",
    "        algo_row_upper = df_results[(df_results['algorithm'] == algo_name) & (df_results['train_size'] == max_train_size)]\n",
    "        df_upper = pd.DataFrame({\n",
    "            'algorithm': [f'{algo_name} upper'] * qnt_train_sizes,\n",
    "            'hits': [algo_row_upper['hits'].values[0]] * qnt_train_sizes,\n",
    "            'hr': [algo_row_upper['hr'].values[0]] * qnt_train_sizes,\n",
    "            'time': [algo_row_upper['time'].values[0]] * qnt_train_sizes,\n",
    "            'train_size': train_sizes,\n",
    "            'test_size': [algo_row_upper['test_size'].values[0]] * qnt_train_sizes,\n",
    "            'test_interactions': [algo_row_upper['test_interactions'].values[0]] * qnt_train_sizes\n",
    "        })\n",
    "        df_results = pd.concat([df_results, df_upper])\n",
    "\n",
    "        df_results = df_results[df_results['algorithm'] != algo_name]\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_results(df_results, save_root):\n",
    "    df_results = remove_incremental(df_results)\n",
    "    df_results = transform_in_upper_and_lower_bounds(df_results, ['ALS', 'BPR'])\n",
    "\n",
    "    algos_configs = {\n",
    "        'ALS upper': {'color': 'blue', 'dash': 'dash'},\n",
    "        'ALS lower': {'color': 'blue', 'dash': 'dash'},\n",
    "        'BPR upper': {'color': 'red', 'dash': 'dash'},\n",
    "        'BPR lower': {'color': 'red', 'dash': 'dash'},\n",
    "        'LinUCB - ALS embeddings': {'color': 'green', 'dash': 'solid'},\n",
    "        'LinUCB - BPR embeddings': {'color': 'purple', 'dash': 'solid'},\n",
    "        'LinGreedy - ALS embeddings': {'color': 'orange', 'dash': 'solid'},\n",
    "        'LinGreedy - BPR embeddings': {'color': 'pink', 'dash': 'solid'}\n",
    "    }\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for algo_name, config in algos_configs.items():\n",
    "        df_algo = df_results[df_results['algorithm'] == algo_name]\n",
    "        fig.add_trace(go.Scatter(x=df_algo['train_size'], y=df_algo['hr'], mode='lines', name=algo_name, line=dict(color=config['color'], dash=config['dash'])))\n",
    "    \n",
    "    fig.update_layout(title='HR x Train size', xaxis_title='Train size', yaxis_title='HR')\n",
    "    fig.show()\n",
    "\n",
    "    fig.write_html(f'{save_root}/hr_x_train_size.html')\n",
    "    fig.write_image(f'{save_root}/hr_x_train_size.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(df_results, 'results-v8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_results, x=\"train_size\", y=\"hr\", color='algorithm', title='HR x Train size')\n",
    "fig.show()\n",
    "fig.write_html('results-v8/hr_x_train_size.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLRS-rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
