{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregorio/.conda/envs/weighted-sims/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gregorio/.conda/envs/weighted-sims/lib/python3.8/site-packages/implicit/gpu/__init__.py:13: UserWarning: CUDA extension is built, but disabling GPU support because of 'Cuda Error: no CUDA-capable device is detected (/project/./implicit/gpu/utils.h:71)'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BaseMAasB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimplicit\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmab2rec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BanditRecommender, LearningPolicy\n",
      "File \u001b[0;32m~/.conda/envs/weighted-sims/lib/python3.8/site-packages/mab2rec/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright FMR LLC <opensource@fidelity.com>\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningPolicy, NeighborhoodPolicy\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BanditRecommender\n",
      "File \u001b[0;32m~/.conda/envs/weighted-sims/lib/python3.8/site-packages/mabwiser/mab.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __author__, __copyright__, __email__, __version__\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapproximate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LSHNearest\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclusters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Clusters\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgreedy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _EpsilonGreedy\n",
      "File \u001b[0;32m~/.conda/envs/weighted-sims/lib/python3.8/site-packages/mabwiser/approximate.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgreedy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _EpsilonGreedy\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Linear\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Neighbors\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmabwiser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopularity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Popularity\n",
      "File \u001b[0;32m~/.conda/envs/weighted-sims/lib/python3.8/site-packages/mabwiser/linear.py:137\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;66;03m# Calculate linucb expectation y = x * b + ucb\u001b[39;00m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta) \u001b[38;5;241m+\u001b[39m ucb\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_Linear\u001b[39;00m(\u001b[43mBaseMAasB\u001b[49m):\n\u001b[1;32m    138\u001b[0m     factory \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m\"\u001b[39m: _LinTS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mucb\u001b[39m\u001b[38;5;124m\"\u001b[39m: _LinUCB, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mridge\u001b[39m\u001b[38;5;124m\"\u001b[39m: _RidgeRegression}\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng: _BaseRNG, arms: List[Arm], n_jobs: \u001b[38;5;28mint\u001b[39m, backend: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    141\u001b[0m                  alpha: Num, epsilon: Num, l2_lambda: Num, regression: \u001b[38;5;28mstr\u001b[39m, scale: \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseMAasB' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "import plotly.express as px\n",
    "import time\n",
    "import os\n",
    "import implicit\n",
    "from mab2rec import BanditRecommender, LearningPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"/workspace/gregorio/reinforcement-learning-recsys/1-datasets/bestbuy/interactions.csv\", sep=';')\n",
    "    df = df.rename(columns={\n",
    "        'id_user': 'user_id',\n",
    "        'id_item': 'item_id',\n",
    "    })\n",
    "    df['response'] = 1\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    df = df[['user_id', 'item_id', 'response']]\n",
    "    df = df.iloc[:int(len(df) * 0.5)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_context(interactions, context_cols):\n",
    "    # Concat multiple array columns into a single array column\n",
    "    return np.array(interactions[context_cols].apply(lambda x: np.concatenate((*x, [1])), axis=1).tolist())  # MUDANÇA: adiciona 1 ao final de cada vetor (bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_mab(mab_algo, df_train_with_contexts, contexts_col):\n",
    "    contexts = get_concat_context(df_train_with_contexts, contexts_col)\n",
    "    mab_algo.fit(\n",
    "        decisions=df_train_with_contexts['item_id'],\n",
    "        rewards=df_train_with_contexts['response'],\n",
    "        contexts=contexts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_list_items_mean(interactions_df, items_embeddings):\n",
    "    users_current_info = {}\n",
    "    contexts = []\n",
    "\n",
    "    for _, row in tqdm(interactions_df.iterrows(), total=len(interactions_df)):\n",
    "        user_id = row[\"user_id\"]\n",
    "        item_id = row[\"item_id\"]\n",
    "\n",
    "        if user_id not in users_current_info:\n",
    "            users_current_info[user_id] = {\n",
    "                'acum_emb': np.zeros((FACTORS, )),\n",
    "                'count': 0\n",
    "            }\n",
    "        \n",
    "        contexts.append(users_current_info[user_id]['acum_emb'] / max(1, users_current_info[user_id]['count']))\n",
    "\n",
    "        users_current_info[user_id]['acum_emb'] += items_embeddings[item_id][:FACTORS]\n",
    "        users_current_info[user_id]['count'] += 1\n",
    "\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_non_incremental(mab_algo, contexts_col, df_test, interactions_by_user):\n",
    "    start_time = time.time()\n",
    "    hits = 0\n",
    "\n",
    "    # contexts = df_test.merge(user_features, how='left', on='user_id').drop(columns=['user_id', 'item_id', 'response']).values\n",
    "    # contexts = np.array(df_test[contexts_col].tolist())\n",
    "    print('entrou')\n",
    "    contexts = get_concat_context(df_test, contexts_col)\n",
    "    filters = df_test.merge(interactions_by_user, how='left', on='user_id')[['interactions']].values.squeeze(axis=1) \n",
    "    print('saiu')\n",
    "\n",
    "    recomendations = mab_algo.recommend(contexts, filters, apply_sigmoid=False)\n",
    "\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    hits = 0\n",
    "    for i, interaction in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "        if interaction['item_id'] in recomendations[i]:\n",
    "            hits += 1\n",
    "    \n",
    "\n",
    "    recs_df = pd.DataFrame({\n",
    "        'interaction_number': [i for i in range(len(df_test))],\n",
    "        'user_id': df_test['user_id'],\n",
    "        'item_id': df_test['item_id'],\n",
    "        'recommendations': recomendations\n",
    "    })\n",
    "\n",
    "    return hits, hits/len(df_test), time.time() - start_time, recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_embeddings_model(Model, df, num_users, num_items, generate_embeddings=False):\n",
    "    sparse_matrix = csr_matrix((df['response'], (df['user_id'], df['item_id'])), shape=(num_users, num_items))\n",
    "\n",
    "    model = Model(factors=FACTORS, random_state=1)\n",
    "    model.fit(sparse_matrix)\n",
    "\n",
    "    if not generate_embeddings:\n",
    "        return model, sparse_matrix\n",
    "    \n",
    "    # # Não precisamos mais do código abaixo, ele funcina para embeddings de usuário, não de itens\n",
    "    # user_features_list = []\n",
    "\n",
    "    # for user_id in df['user_id'].unique():\n",
    "    #    user_factors = model.user_factors[user_id][:FACTORS]  # O BPR coloca 1 no final dos vetores latentes ?\n",
    "    #    user_features_list.append([user_id] + list(user_factors))\n",
    "\n",
    "    # df_user_features = pd.DataFrame(user_features_list, columns=['user_id'] + [f'u{i}' for i in range(FACTORS)])\n",
    "\n",
    "    # model = model.to_cpu()\n",
    "    return model, sparse_matrix, model.item_factors, model.user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_interactions_by_user(interactions_df):\n",
    "    interactions_by_user = interactions_df\\\n",
    "                        .groupby('user_id')[['item_id']]\\\n",
    "                        .apply(lambda df_user: df_user['item_id'].tolist())\\\n",
    "                        .reset_index(name='interactions')\n",
    "    interactions_by_user = interactions_by_user.reset_index(drop=True)\n",
    "    return interactions_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932629</th>\n",
       "      <td>647092</td>\n",
       "      <td>40832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932630</th>\n",
       "      <td>647093</td>\n",
       "      <td>41655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932631</th>\n",
       "      <td>647094</td>\n",
       "      <td>790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932632</th>\n",
       "      <td>647095</td>\n",
       "      <td>1803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932633</th>\n",
       "      <td>647082</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932634 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  response\n",
       "0             0        0         1\n",
       "1             1        1         1\n",
       "2             2        2         1\n",
       "3             3        3         1\n",
       "4             4        4         1\n",
       "...         ...      ...       ...\n",
       "932629   647092    40832         1\n",
       "932630   647093    41655         1\n",
       "932631   647094      790         1\n",
       "932632   647095     1803         1\n",
       "932633   647082      484         1\n",
       "\n",
       "[932634 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = load_data()\n",
    "\n",
    "# Troquei o labelEnconder pois ele não fazia na ordem (item_id primeiro a parecer precisa ser o 0, dps o 1, etc)\n",
    "df_full['user_id'] = pd.factorize(df_full['user_id'])[0]\n",
    "df_full['item_id'] = pd.factorize(df_full['item_id'])[0]\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = df_full['user_id'].nunique()\n",
    "num_items = df_full['item_id'].nunique()\n",
    "\n",
    "split_index = int(len(df_full) * (1 - 0.1))\n",
    "df_train_full = df_full[:split_index]\n",
    "df_test = df_full[split_index:]\n",
    "\n",
    "initial_df_train = df_train_full[:int(len(df_train_full) * 0.5)]\n",
    "extra_df_train = df_train_full[int(len(df_train_full) * 0.5):]\n",
    "extra_df_train = extra_df_train[(extra_df_train['user_id'].isin(initial_df_train['user_id'])) & (extra_df_train['item_id'].isin(initial_df_train['item_id']))]\n",
    "extra_df_train = extra_df_train.reset_index(drop=True)\n",
    "\n",
    "df_test = df_test[(df_test['user_id'].isin(initial_df_train['user_id'])) & (df_test['item_id'].isin(initial_df_train['item_id']))]\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_test_for_evaluation = df_test[df_test['response'] == 1]\n",
    "df_test_for_evaluation = df_test_for_evaluation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:36<00:00,  2.42s/it]\n",
      "100%|██████████| 461136/461136 [00:31<00:00, 14769.70it/s]\n",
      "/tmp/ipykernel_45979/664699790.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_df_train['items_mean'] = als_contexts[:len(initial_df_train)]\n"
     ]
    }
   ],
   "source": [
    "df_full_new = pd.concat([initial_df_train, extra_df_train, df_test_for_evaluation])\n",
    "ALS_model, _, ALS_item_embeddings, ALS_user_embeddings = train_embeddings_model(implicit.als.AlternatingLeastSquares, initial_df_train, num_users, num_items, generate_embeddings=True)\n",
    "als_contexts = create_contexts_list_items_mean(df_full_new, ALS_item_embeddings)\n",
    "\n",
    "initial_df_train['items_mean'] = als_contexts[:len(initial_df_train)]\n",
    "\n",
    "extra_df_train['items_mean'] = als_contexts[len(initial_df_train):len(initial_df_train) + len(extra_df_train)]\n",
    "\n",
    "df_test_for_evaluation['items_mean'] = als_contexts[len(initial_df_train) + len(extra_df_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df_train = initial_df_train\n",
    "interactions_by_user = group_interactions_by_user(current_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinGreedy - ALS embeddings\n",
      "arm_to_model demorou -0.38626527786254883\n",
      "reset_arm_to_status demorou -0.01086878776550293\n",
      "paralel fit demorou -20.893952131271362\n",
      "_set_arms_as_trained acabou em -8.390342473983765 segundos\n",
      "Treino demorou 33.76591157913208\n",
      "Testing LinGreedy - ALS embeddings\n",
      "entrou\n",
      "saiu\n",
      "oi1\n",
      "Gerando as predições\n",
      "Gerar as predições demorou 3.563124179840088 segundos\n",
      "Formatando as predições\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:14<00:00, 255.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatação demorou 14.898889064788818 segundos\n",
      "predict_expectations demorou 18.509413957595825 segundos\n",
      "oi2\n",
      "transformação das expectativas demorou 38.621105670928955 segundos\n",
      "oi3\n",
      "criando matriz de exclusão de arms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 238510.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fazendo o restante\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O restante demorou 8.507043838500977 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 15915.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Training LinGreedy - ALS embeddings')\n",
    "linGreedy_model = BanditRecommender(learning_policy=LearningPolicy.LinGreedy(epsilon=0.01), top_k=10)\n",
    "start_time = time.time()\n",
    "train_mab(linGreedy_model, current_df_train, ['items_mean'])\n",
    "print(f'Treino demorou {time.time() - start_time}')\n",
    "\n",
    "print(f'Testing LinGreedy - ALS embeddings')\n",
    "hits, hr, spent_time, df_recs_linGreedy = test_non_incremental(linGreedy_model, ['items_mean'], df_test_for_evaluation, interactions_by_user)\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mabwiser.linear import _Linear\n",
    "from mabwiser.utils import Num, _BaseRNG\n",
    "from typing import List, Optional\n",
    "\n",
    "class _LinearArmEncoded(_Linear):\n",
    "\n",
    "    def __init__(self, rng: _BaseRNG, num_arms: int, n_jobs: int, backend: Optional[str],\n",
    "                 alpha: Num, epsilon: Num, l2_lambda: Num, regression: str, scale: bool):\n",
    "        super().__init__(rng, np.arange(num_arms).tolist(), n_jobs, backend, alpha, epsilon, l2_lambda, regression, scale)\n",
    "        self.num_arms = num_arms\n",
    "    \n",
    "    def _vectorized_predict_context(self, contexts: np.ndarray, is_predict: bool) -> List:\n",
    "\n",
    "        arms = np.arange(self.num_arms)\n",
    "\n",
    "        # Initializing array with expectations for each arm\n",
    "        num_contexts = contexts.shape[0]\n",
    "        arm_expectations = np.empty((num_contexts, self.num_arms), dtype=float)\n",
    "\n",
    "        # With epsilon probability, assign random flag to context\n",
    "        random_values = self.rng.rand(num_contexts)\n",
    "        random_mask = np.array(random_values < self.epsilon)\n",
    "        random_indices = random_mask.nonzero()[0]\n",
    "\n",
    "        # For random indices, generate random expectations\n",
    "        arm_expectations[random_indices] = self.rng.rand((random_indices.shape[0], self.num_arms))\n",
    "\n",
    "        # For non-random indices, get expectations for each arm\n",
    "        nonrandom_indices = np.where(~random_mask)[0]\n",
    "        nonrandom_context = contexts[nonrandom_indices]\n",
    "        print('Gerando as predições')\n",
    "        start_time = time.time()\n",
    "        arm_expectations[nonrandom_indices] = np.array([self.arm_to_model[arm].predict(nonrandom_context)\n",
    "                                                        for arm in arms]).T\n",
    "        print(f'Gerar as predições demorou {time.time() - start_time} segundos')\n",
    "\n",
    "        return arm_expectations if len(arm_expectations) > 1 else arm_expectations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mabwiser.mab import MAB, LearningPolicyType, NeighborhoodPolicyType, NeighborhoodPolicy\n",
    "from typing import List\n",
    "\n",
    "from mabwiser._version import __author__, __copyright__, __email__, __version__\n",
    "from mabwiser.approximate import _LSHNearest\n",
    "from mabwiser.clusters import _Clusters\n",
    "from mabwiser.greedy import _EpsilonGreedy\n",
    "from mabwiser.linear import _Linear\n",
    "from mabwiser.neighbors import _KNearest, _Radius\n",
    "from mabwiser.popularity import _Popularity\n",
    "from mabwiser.rand import _Random\n",
    "from mabwiser.softmax import _Softmax\n",
    "from mabwiser.thompson import _ThompsonSampling\n",
    "from mabwiser.treebandit import _TreeBandit\n",
    "from mabwiser.ucb import _UCB1\n",
    "from mabwiser.utils import Arm, Constants, check_true, create_rng\n",
    "\n",
    "class MABArmEncoded(MAB):\n",
    "    def __init__(self,\n",
    "                 num_arms: int,  # The list of arms\n",
    "                 learning_policy: LearningPolicyType,  # The learning policy\n",
    "                 neighborhood_policy: NeighborhoodPolicyType = None,  # The context policy, optional\n",
    "                 seed: int = Constants.default_seed,  # The random seed\n",
    "                 n_jobs: int = 1,  # Number of parallel jobs\n",
    "                 backend: str = None  # Parallel backend implementation\n",
    "                 ):\n",
    "        \"\"\"Initializes a multi-armed bandit (MAB) with the given arguments.\n",
    "\n",
    "        Validates the arguments and raises exception in case there are violations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        arms : List[Union[int, float, str]]\n",
    "            The list of all the arms available for decisions.\n",
    "            Arms can be integers, strings, etc.\n",
    "        learning_policy : LearningPolicyType\n",
    "            The learning policy.\n",
    "        neighborhood_policy : NeighborhoodPolicyType, optional\n",
    "            The context policy. Default value is None.\n",
    "        seed : numbers.Rational, optional\n",
    "            The random seed to initialize the random number generator.\n",
    "            Default value is set to Constants.default_seed.value\n",
    "        n_jobs: int, optional\n",
    "            This is used to specify how many concurrent processes/threads should be used for parallelized routines.\n",
    "            Default value is set to 1.\n",
    "            If set to -1, all CPUs are used.\n",
    "            If set to -2, all CPUs but one are used, and so on.\n",
    "        backend: str, optional\n",
    "            Specify a parallelization backend implementation supported in the joblib library. Supported options are:\n",
    "            - “loky” used by default, can induce some communication and memory overhead when exchanging input and\n",
    "              output data with the worker Python processes.\n",
    "            - “multiprocessing” previous process-based backend based on multiprocessing.Pool. Less robust than loky.\n",
    "            - “threading” is a very low-overhead backend but it suffers from the Python Global Interpreter Lock if the\n",
    "              called function relies a lot on Python objects.\n",
    "            Default value is None. In this case the default backend selected by joblib will be used.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError:  Arms were not provided in a list.\n",
    "        TypeError:  Learning policy type mismatch.\n",
    "        TypeError:  Context policy type mismatch.\n",
    "        TypeError:  Seed is not an integer.\n",
    "        TypeError:  Number of parallel jobs is not an integer.\n",
    "        TypeError:  Parallel backend is not a string.\n",
    "        TypeError:  For EpsilonGreedy, epsilon must be integer or float.\n",
    "        TypeError:  For LinGreedy, epsilon must be an integer or float.\n",
    "        TypeError:  For LinGreedy, l2_lambda must be an integer or float.\n",
    "        TypeError:  For LinTS, alpha must be an integer or float.\n",
    "        TypeError:  For LinTS, l2_lambda must be an integer or float.\n",
    "        TypeError:  For LinUCB, alpha must be an integer or float.\n",
    "        TypeError:  For LinUCB, l2_lambda must be an integer or float.\n",
    "        TypeError:  For Softmax, tau must be an integer or float.\n",
    "        TypeError:  For ThompsonSampling, binarizer must be a callable function.\n",
    "        TypeError:  For UCB, alpha must be an integer or float.\n",
    "        TypeError:  For LSHNearest, n_dimensions must be an integer or float.\n",
    "        TypeError:  For LSHNearest, n_tables must be an integer or float.\n",
    "        TypeError:  For LSHNearest, no_nhood_prob_of_arm must be None or List that sums up to 1.0.\n",
    "        TypeError:  For Clusters, n_clusters must be an integer.\n",
    "        TypeError:  For Clusters, is_minibatch must be a boolean.\n",
    "        TypeError:  For Radius, radius must be an integer or float.\n",
    "        TypeError:  For Radius, no_nhood_prob_of_arm must be None or List that sums up to 1.0.\n",
    "        TypeError:  For KNearest, k must be an integer or float.\n",
    "\n",
    "        ValueError: Invalid number of arms.\n",
    "        ValueError: Invalid values (None, NaN, Inf) in arms.\n",
    "        ValueError: Duplicate values in arms.\n",
    "        ValueError: Number of parallel jobs is 0.\n",
    "        ValueError: For EpsilonGreedy, epsilon must be between 0 and 1.\n",
    "        ValueError: For LinGreedy, epsilon must be between 0 and 1.\n",
    "        ValueError: For LinGreedy, l2_lambda cannot be negative.\n",
    "        ValueError: For LinTS, alpha must be greater than zero.\n",
    "        ValueError: For LinTS, l2_lambda must be greater than zero.\n",
    "        ValueError: For LinUCB, alpha cannot be negative.\n",
    "        ValueError: For LinUCB, l2_lambda cannot be negative.\n",
    "        ValueError: For Softmax, tau must be greater than zero.\n",
    "        ValueError: For UCB, alpha must be greater than zero.\n",
    "        ValueError: For LSHNearest, n_dimensions must be gerater than zero.\n",
    "        ValueError: For LSHNearest, n_tables must be gerater than zero.\n",
    "        ValueError: For LSHNearest, if given, no_nhood_prob_of_arm list should sum up to 1.0.\n",
    "        ValueError: For Clusters, n_clusters cannot be less than 2.\n",
    "        ValueError: For Radius and KNearest, metric is not supported by scipy.spatial.distance.cdist.\n",
    "        ValueError: For Radius, radius must be greater than zero.\n",
    "        ValueError: For Radius, if given, no_nhood_prob_of_arm list should sum up to 1.0.\n",
    "        ValueError: For KNearest, k must be greater than zero.\n",
    "        \"\"\"\n",
    "\n",
    "        # Validate arguments\n",
    "        # MAB._validate_mab_args(arms, learning_policy, neighborhood_policy, seed, n_jobs, backend)\n",
    "\n",
    "        # Save the arguments\n",
    "        self.arms = np.arange(num_arms)\n",
    "        self.num_arms = num_arms\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs\n",
    "        self.backend = backend\n",
    "\n",
    "        # Create the random number generator\n",
    "        self._rng = create_rng(self.seed)\n",
    "        self._is_initial_fit = False\n",
    "\n",
    "        # Create the learning policy implementor\n",
    "        lp = None\n",
    "        if isinstance(learning_policy, LearningPolicy.EpsilonGreedy):\n",
    "            lp = _EpsilonGreedy(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.epsilon)\n",
    "        elif isinstance(learning_policy, LearningPolicy.Popularity):\n",
    "            lp = _Popularity(self._rng, self.arms, self.n_jobs, self.backend)\n",
    "        elif isinstance(learning_policy, LearningPolicy.Random):\n",
    "            lp = _Random(self._rng, self.arms, self.n_jobs, self.backend)\n",
    "        elif isinstance(learning_policy, LearningPolicy.Softmax):\n",
    "            lp = _Softmax(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.tau)\n",
    "        elif isinstance(learning_policy, LearningPolicy.ThompsonSampling):\n",
    "            lp = _ThompsonSampling(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.binarizer)\n",
    "        elif isinstance(learning_policy, LearningPolicy.UCB1):\n",
    "            lp = _UCB1(self._rng, self.arms, self.n_jobs, self.backend, learning_policy.alpha)\n",
    "        elif isinstance(learning_policy, LearningPolicy.LinGreedy):\n",
    "            lp = _LinearArmEncoded(self._rng, num_arms, self.n_jobs, self.backend, 0, learning_policy.epsilon,\n",
    "                         learning_policy.l2_lambda, \"ridge\", learning_policy.scale)\n",
    "        elif isinstance(learning_policy, LearningPolicy.LinTS):\n",
    "            lp = _LinearArmEncoded(self._rng, num_arms, self.n_jobs, self.backend, learning_policy.alpha, 0,\n",
    "                         learning_policy.l2_lambda, \"ts\", learning_policy.scale)\n",
    "        elif isinstance(learning_policy, LearningPolicy.LinUCB):\n",
    "            lp = _LinearArmEncoded(self._rng, num_arms, self.n_jobs, self.backend, learning_policy.alpha, 0,\n",
    "                         learning_policy.l2_lambda, \"ucb\", learning_policy.scale)\n",
    "        else:\n",
    "            check_true(False, ValueError(\"Undefined learning policy \" + str(learning_policy)))\n",
    "\n",
    "        # Create the mab implementor\n",
    "        if neighborhood_policy:\n",
    "            self.is_contextual = True\n",
    "\n",
    "            # Do not use parallel fit or predict for Learning Policy when contextual\n",
    "            lp.n_jobs = 1\n",
    "\n",
    "            if isinstance(neighborhood_policy, NeighborhoodPolicy.Clusters):\n",
    "                self._imp = _Clusters(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                      neighborhood_policy.n_clusters, neighborhood_policy.is_minibatch)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.LSHNearest):\n",
    "                self._imp = _LSHNearest(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                        neighborhood_policy.n_dimensions, neighborhood_policy.n_tables,\n",
    "                                        neighborhood_policy.no_nhood_prob_of_arm)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.KNearest):\n",
    "                self._imp = _KNearest(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                      neighborhood_policy.k, neighborhood_policy.metric)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.Radius):\n",
    "                self._imp = _Radius(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                    neighborhood_policy.radius, neighborhood_policy.metric,\n",
    "                                    neighborhood_policy.no_nhood_prob_of_arm)\n",
    "            elif isinstance(neighborhood_policy, NeighborhoodPolicy.TreeBandit):\n",
    "                self._imp = _TreeBandit(self._rng, self.arms, self.n_jobs, self.backend, lp,\n",
    "                                        neighborhood_policy.tree_parameters)\n",
    "            else:\n",
    "                check_true(False, ValueError(\"Undefined context policy \" + str(neighborhood_policy)))\n",
    "        else:\n",
    "            self.is_contextual = isinstance(learning_policy, (LearningPolicy.LinGreedy, LearningPolicy.LinTS,\n",
    "                                                              LearningPolicy.LinUCB))\n",
    "            self._imp = lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arm_to_model demorou -0.3874397277832031\n",
      "reset_arm_to_status demorou -0.01585555076599121\n",
      "paralel fit demorou -20.164703130722046\n",
      "_set_arms_as_trained acabou em -19.889243602752686 segundos\n"
     ]
    }
   ],
   "source": [
    "mab_arm_encoded = MABArmEncoded(initial_df_train['item_id'].nunique(), LearningPolicy.LinGreedy(epsilon=0.01))\n",
    "contexts = get_concat_context(initial_df_train, ['items_mean'])\n",
    "mab_arm_encoded.fit(\n",
    "    decisions=initial_df_train['item_id'],\n",
    "    rewards=initial_df_train['response'],\n",
    "    contexts=contexts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando as predições\n",
      "Gerar as predições demorou 0.12679529190063477 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99635754, 0.99859976, 0.86409422, ..., 0.5       , 0.5       ,\n",
       "       0.49999844])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_expecs = mab_arm_encoded.predict_expectations([contexts[0]])\n",
    "new_expecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando as predições\n",
      "Gerar as predições demorou 0.13171768188476562 segundos\n",
      "Formatando as predições\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 286.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatação demorou 0.007084369659423828 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.9963575424544597,\n",
       " 1: 0.9985997585810332,\n",
       " 2: 0.8640942205254151,\n",
       " 3: 0.799999165890977,\n",
       " 4: 0.9822321485685649,\n",
       " 5: 0.5,\n",
       " 6: 0.9996184040604488,\n",
       " 7: 0.998860461502671,\n",
       " 8: 0.9795916261831876,\n",
       " 9: 0.9898917955916612,\n",
       " 10: 0.9993227683651622,\n",
       " 11: 0.9913797366180096,\n",
       " 12: 0.5,\n",
       " 13: 0.49999547283463697,\n",
       " 14: 0.9891206264013634,\n",
       " 15: 0.499998866739919,\n",
       " 16: 0.9751891830633864,\n",
       " 17: 0.9991877428935969,\n",
       " 18: 0.7999823412917986,\n",
       " 19: 0.9814812692926982,\n",
       " 20: 0.9861528263620142,\n",
       " 21: 0.6666664425251037,\n",
       " 22: 0.9910382915044242,\n",
       " 23: 0.9729729242689892,\n",
       " 24: 0.8337360802917398,\n",
       " 25: 0.9992895408863376,\n",
       " 26: 0.9946803367288888,\n",
       " 27: 0.9609673766575105,\n",
       " 28: 0.9285714284576941,\n",
       " 29: 0.9926189596240598,\n",
       " 30: 0.5,\n",
       " 31: 0.9950856534883689,\n",
       " 32: 0.9166656025199647,\n",
       " 33: 0.499997804507997,\n",
       " 34: 0.909083384234908,\n",
       " 35: 0.9375229072465072,\n",
       " 36: 0.9967911500906883,\n",
       " 37: 0.9976596026275447,\n",
       " 38: 0.999618902392124,\n",
       " 39: 0.8333333333333333,\n",
       " 40: 0.7499999864352241,\n",
       " 41: 0.9993090162684857,\n",
       " 42: 0.7999931342893017,\n",
       " 43: 0.996388577595173,\n",
       " 44: 0.9977433448234962,\n",
       " 45: 0.9949376770696992,\n",
       " 46: 0.49923882661819297,\n",
       " 47: 0.985585274806137,\n",
       " 48: 0.9787229708747027,\n",
       " 49: 0.9948116251666892,\n",
       " 50: 0.21818395137902685,\n",
       " 51: 0.8133543474164143,\n",
       " 52: 0.3012085504254811,\n",
       " 53: 0.9285713767937747,\n",
       " 54: 0.9952131518649603,\n",
       " 55: 0.7499997564274666,\n",
       " 56: 0.9903845550298433,\n",
       " 57: 0.9901000678308847,\n",
       " 58: 0.9090909090874988,\n",
       " 59: 0.9918322088003788,\n",
       " 60: 0.5,\n",
       " 61: 0.9948941604001558,\n",
       " 62: 0.9988991512114138,\n",
       " 63: 0.9411764656137498,\n",
       " 64: 0.9975454488592286,\n",
       " 65: 0.9852825636740067,\n",
       " 66: 0.9996380734065551,\n",
       " 67: 0.977777462974052,\n",
       " 68: 0.9230464699438462,\n",
       " 69: 0.9721632472566711,\n",
       " 70: 0.9798777876357073,\n",
       " 71: 0.9616528825899339,\n",
       " 72: 0.9901971359341447,\n",
       " 73: 0.9545452251402673,\n",
       " 74: 0.9915048075905086,\n",
       " 75: 0.9980973210173545,\n",
       " 76: 0.9952419023148359,\n",
       " 77: 0.9900396630751528,\n",
       " 78: 0.5,\n",
       " 79: 0.9545453482703138,\n",
       " 80: 0.6666659289073018,\n",
       " 81: 0.9970071766942646,\n",
       " 82: 0.875,\n",
       " 83: 0.9953511860674967,\n",
       " 84: 0.9565183663047337,\n",
       " 85: 0.9807691006641795,\n",
       " 86: 0.9924807131653968,\n",
       " 87: 0.9941689944684367,\n",
       " 88: 0.9940604670785355,\n",
       " 89: 0.9999477742960692,\n",
       " 90: 0.9767440368118319,\n",
       " 91: 0.9991575585863931,\n",
       " 92: 0.991562035505911,\n",
       " 93: 0.5,\n",
       " 94: 0.9976381713625762,\n",
       " 95: 0.9991774526900821,\n",
       " 96: 0.9885047198474384,\n",
       " 97: 0.9961897587614236,\n",
       " 98: 0.909090908768312,\n",
       " 99: 0.954540382755283,\n",
       " 100: 0.9655151634492555,\n",
       " 101: 0.9978835976720316,\n",
       " 102: 0.8749999999994,\n",
       " 103: 0.9880251518467101,\n",
       " 104: 0.9971587194890293,\n",
       " 105: 0.9565238452970561,\n",
       " 106: 0.9949976008578705,\n",
       " 107: 0.9993277374784795,\n",
       " 108: 0.9954365840354901,\n",
       " 109: 0.9954931493197626,\n",
       " 110: 0.996809108914277,\n",
       " 111: 0.9921246997472307,\n",
       " 112: 0.8,\n",
       " 113: 0.9985078379341643,\n",
       " 114: 0.985293944452092,\n",
       " 115: 0.7998872493964108,\n",
       " 116: 0.8999999989428682,\n",
       " 117: 0.9965209307610714,\n",
       " 118: 0.9906500761268051,\n",
       " 119: 0.9980564652101931,\n",
       " 120: 0.9639717855336206,\n",
       " 121: 0.9772397087706776,\n",
       " 122: 0.5,\n",
       " 123: 0.6666622556260958,\n",
       " 124: 0.9889329189857112,\n",
       " 125: 0.9874158155616576,\n",
       " 126: 0.9951664590411047,\n",
       " 127: 0.6666666666666666,\n",
       " 128: 0.982138365609945,\n",
       " 129: 0.97872048005698,\n",
       " 130: 0.9943789464847926,\n",
       " 131: 0.8999999585765903,\n",
       " 132: 0.5,\n",
       " 133: 0.952379897376537,\n",
       " 134: 0.9972403467088097,\n",
       " 135: 0.8749829578372295,\n",
       " 136: 0.9927494076890726,\n",
       " 137: 0.6666666666666666,\n",
       " 138: 0.8999971812713349,\n",
       " 139: 0.9743559690421266,\n",
       " 140: 0.9893606093558324,\n",
       " 141: 0.9987294301049155,\n",
       " 142: 0.9666658023388045,\n",
       " 143: 0.9578420219045931,\n",
       " 144: 0.8747884831559751,\n",
       " 145: 0.9960394831266424,\n",
       " 146: 0.9886136556237881,\n",
       " 147: 0.9617195080192046,\n",
       " 148: 0.9333330829280941,\n",
       " 149: 0.9186306787039719,\n",
       " 150: 0.9978484200813023,\n",
       " 151: 0.9933760000269717,\n",
       " 152: 0.9956363559789861,\n",
       " 153: 0.9967633371872424,\n",
       " 154: 0.9166467610020342,\n",
       " 155: 0.7999999999999998,\n",
       " 156: 0.5,\n",
       " 157: 0.9929631016268798,\n",
       " 158: 0.9988744640511117,\n",
       " 159: 0.9919276341331096,\n",
       " 160: 0.9936140021162634,\n",
       " 161: 0.9333225836671618,\n",
       " 162: 0.989689422140598,\n",
       " 163: 0.9666652046396669,\n",
       " 164: 0.9867968697169827,\n",
       " 165: 0.6666666347984004,\n",
       " 166: 0.9615383032923911,\n",
       " 167: 0.9966340957139959,\n",
       " 168: 0.9705111743565775,\n",
       " 169: 0.9583189281006311,\n",
       " 170: 0.9166666666666666,\n",
       " 171: 0.9473683633182151,\n",
       " 172: 0.8569922588766384,\n",
       " 173: 0.9963928055186084,\n",
       " 174: 0.9948977379003274,\n",
       " 175: 0.9843094813402774,\n",
       " 176: 0.8333329072311232,\n",
       " 177: 0.9942661366211519,\n",
       " 178: 0.9407532920230862,\n",
       " 179: 0.9974069475324303,\n",
       " 180: 0.8333333283039126,\n",
       " 181: 0.9972915072552082,\n",
       " 182: 0.5,\n",
       " 183: 0.9948784853471944,\n",
       " 184: 0.8749998501526259,\n",
       " 185: 0.8885136371434531,\n",
       " 186: 0.9230751981150499,\n",
       " 187: 0.9696819232602806,\n",
       " 188: 0.9989100487441852,\n",
       " 189: 0.9599989696158042,\n",
       " 190: 0.9736732015937479,\n",
       " 191: 0.9166665507696036,\n",
       " 192: 0.909090909090879,\n",
       " 193: 0.993409994901966,\n",
       " 194: 0.9870110949536707,\n",
       " 195: 0.9523808482253148,\n",
       " 196: 0.9444423686214248,\n",
       " 197: 0.9666739014385091,\n",
       " 198: 0.9954697886276552,\n",
       " 199: 0.9854629505843854,\n",
       " 200: 0.75,\n",
       " 201: 0.9714281933953571,\n",
       " 202: 0.9940775829904207,\n",
       " 203: 0.9957647402087367,\n",
       " 204: 0.9092519660300622,\n",
       " 205: 0.9333332465320411,\n",
       " 206: 0.9629628513742146,\n",
       " 207: 0.9964523766030556,\n",
       " 208: 0.962836702973802,\n",
       " 209: 0.9982603915172376,\n",
       " 210: 0.9880781447384622,\n",
       " 211: 0.9836637362016956,\n",
       " 212: 0.9954010753986089,\n",
       " 213: 0.5,\n",
       " 214: 0.9913023875569972,\n",
       " 215: 0.75,\n",
       " 216: 0.9705541098381621,\n",
       " 217: 0.9931119450356658,\n",
       " 218: 0.6666666666666666,\n",
       " 219: 0.9968464048110244,\n",
       " 220: 0.9952217652957008,\n",
       " 221: 0.9166642248121504,\n",
       " 222: 0.995885838968833,\n",
       " 223: 0.937499999992169,\n",
       " 224: 0.9722142032682936,\n",
       " 225: 0.8571427287051325,\n",
       " 226: 0.9687499886250415,\n",
       " 227: 0.9934538791161521,\n",
       " 228: 0.7999999371225914,\n",
       " 229: 0.9923588726708661,\n",
       " 230: 0.8888470972628526,\n",
       " 231: 0.9443475919412224,\n",
       " 232: 0.5,\n",
       " 233: 0.9983951632836348,\n",
       " 234: 0.5,\n",
       " 235: 0.9333332083005131,\n",
       " 236: 0.8075336756593137,\n",
       " 237: 0.8888883452343924,\n",
       " 238: 0.6666666666666666,\n",
       " 239: 0.9924187647936139,\n",
       " 240: 0.9696963640666111,\n",
       " 241: 0.9697252310471934,\n",
       " 242: 0.992479711818723,\n",
       " 243: 0.9782427925423893,\n",
       " 244: 0.9821407368189584,\n",
       " 245: 0.9985787183406339,\n",
       " 246: 0.9615384538155236,\n",
       " 247: 0.992484846655586,\n",
       " 248: 0.9967401379810259,\n",
       " 249: 0.5,\n",
       " 250: 0.9600324682785644,\n",
       " 251: 0.992742501299819,\n",
       " 252: 0.9975097900106383,\n",
       " 253: 0.5,\n",
       " 254: 0.9989787386740501,\n",
       " 255: 0.994736874332658,\n",
       " 256: 0.8749997098644942,\n",
       " 257: 0.9950235062389282,\n",
       " 258: 0.5,\n",
       " 259: 0.9855045771394025,\n",
       " 260: 0.75,\n",
       " 261: 0.9705878949678991,\n",
       " 262: 0.99785967439582,\n",
       " 263: 0.995735927111977,\n",
       " 264: 0.9362454836428625,\n",
       " 265: 0.8571426258411013,\n",
       " 266: 0.7499999998386646,\n",
       " 267: 0.9940824343840036,\n",
       " 268: 0.980696468307262,\n",
       " 269: 0.6666666666666666,\n",
       " 270: 0.8999701439651776,\n",
       " 271: 0.9968949543439296,\n",
       " 272: 0.9926232221153178,\n",
       " 273: 0.9976180239226095,\n",
       " 274: 0.8888887406310683,\n",
       " 275: 0.9974564422122071,\n",
       " 276: 0.9382476685028232,\n",
       " 277: 0.9977818022624386,\n",
       " 278: 0.9230768155384446,\n",
       " 279: 0.9976400799929751,\n",
       " 280: 0.75,\n",
       " 281: 0.9873490698512019,\n",
       " 282: 0.98969018169626,\n",
       " 283: 0.9907403280066585,\n",
       " 284: 0.9956544472502863,\n",
       " 285: 0.9164737093001525,\n",
       " 286: 0.8888888888888888,\n",
       " 287: 0.5,\n",
       " 288: 0.9953017714481451,\n",
       " 289: 0.9930322094266051,\n",
       " 290: 0.99654015288265,\n",
       " 291: 0.7499999999693142,\n",
       " 292: 0.874999927104913,\n",
       " 293: 0.9499982500369232,\n",
       " 294: 0.9915246226488138,\n",
       " 295: 0.9444442255905418,\n",
       " 296: 0.9973278797083398,\n",
       " 297: 0.833333333320359,\n",
       " 298: 0.9981303449092451,\n",
       " 299: 0.9983899655215053,\n",
       " 300: 0.9799987874904791,\n",
       " 301: 0.9411723056450289,\n",
       " 302: 0.9729721783889411,\n",
       " 303: 0.989107316290027,\n",
       " 304: 0.9866660835925233,\n",
       " 305: 0.9880950766574647,\n",
       " 306: 0.959999802900341,\n",
       " 307: 0.909090908537739,\n",
       " 308: 0.9444444357516314,\n",
       " 309: 0.8999999808057091,\n",
       " 310: 0.9772727029944281,\n",
       " 311: 0.875,\n",
       " 312: 0.9411763079287743,\n",
       " 313: 0.899992287848505,\n",
       " 314: 0.9705882202275508,\n",
       " 315: 0.9946515969755388,\n",
       " 316: 0.9852940896504634,\n",
       " 317: 0.9446643722689854,\n",
       " 318: 0.9972980491000992,\n",
       " 319: 0.9166665712509946,\n",
       " 320: 0.9852925571085006,\n",
       " 321: 0.8333333333333333,\n",
       " 322: 0.9953190038837756,\n",
       " 323: 0.9903275173947552,\n",
       " 324: 0.9166610208731928,\n",
       " 325: 0.9231683940821194,\n",
       " 326: 0.9907234383906068,\n",
       " 327: 0.9961679833008827,\n",
       " 328: 0.6666666666666666,\n",
       " 329: 0.96296246431076,\n",
       " 330: 0.9937952075254526,\n",
       " 331: 0.9583331705368144,\n",
       " 332: 0.9285714228712457,\n",
       " 333: 0.9966785832367644,\n",
       " 334: 0.937487962209463,\n",
       " 335: 0.950619741121216,\n",
       " 336: 0.9411764525175202,\n",
       " 337: 0.9917342969288514,\n",
       " 338: 0.9756097367921182,\n",
       " 339: 0.998261802580793,\n",
       " 340: 0.9326165662785872,\n",
       " 341: 0.5,\n",
       " 342: 0.5,\n",
       " 343: 0.9333286847197751,\n",
       " 344: 0.9971191741790164,\n",
       " 345: 0.9956975270390062,\n",
       " 346: 0.9949947489310954,\n",
       " 347: 0.996168114768589,\n",
       " 348: 0.9939809847435452,\n",
       " 349: 0.9959841803670887,\n",
       " 350: 0.8333307252172463,\n",
       " 351: 0.989580066314834,\n",
       " 352: 0.9799979535295443,\n",
       " 353: 0.9975833503282615,\n",
       " 354: 0.9705877742258229,\n",
       " 355: 0.9923663250916915,\n",
       " 356: 0.9285713984348533,\n",
       " 357: 0.9910730082020752,\n",
       " 358: 0.9961063408353903,\n",
       " 359: 0.9968884712089137,\n",
       " 360: 0.9971752825304563,\n",
       " 361: 0.9973569112961276,\n",
       " 362: 0.9958224482509379,\n",
       " 363: 0.9961092016539581,\n",
       " 364: 0.9499994067692131,\n",
       " 365: 0.9893728076962176,\n",
       " 366: 0.970555062325777,\n",
       " 367: 0.9986846410578685,\n",
       " 368: 0.9886358999420483,\n",
       " 369: 0.9960045807178679,\n",
       " 370: 0.5,\n",
       " 371: 0.9964545412244409,\n",
       " 372: 0.8885555313068338,\n",
       " 373: 0.9611256703615128,\n",
       " 374: 0.49999999999999123,\n",
       " 375: 0.9787946294589113,\n",
       " 376: 0.6666666666666666,\n",
       " 377: 0.9523808100202105,\n",
       " 378: 0.9843664843492187,\n",
       " 379: 0.9736839873044398,\n",
       " 380: 0.9599997594394587,\n",
       " 381: 0.9090907457373498,\n",
       " 382: 0.9333333333332513,\n",
       " 383: 0.8749999999769524,\n",
       " 384: 0.9677419047318319,\n",
       " 385: 0.8333322724795472,\n",
       " 386: 0.9229776289502724,\n",
       " 387: 0.9854487007478548,\n",
       " 388: 0.9852993526031678,\n",
       " 389: 0.9782603668281796,\n",
       " 390: 0.9926507640580958,\n",
       " 391: 0.9835884234308038,\n",
       " 392: 0.9761605872976415,\n",
       " 393: 0.9892051757614646,\n",
       " 394: 0.9777403649089191,\n",
       " 395: 0.9923388333592021,\n",
       " 396: 0.9584821782133615,\n",
       " 397: 0.9995368646711528,\n",
       " 398: 0.9966628240224588,\n",
       " 399: 0.9616062764117479,\n",
       " 400: 0.9969814476646852,\n",
       " 401: 0.9970221049940781,\n",
       " 402: 0.9814841993760751,\n",
       " 403: 0.9814711039190498,\n",
       " 404: 0.5,\n",
       " 405: 0.9924806169674788,\n",
       " 406: 0.9905960781259006,\n",
       " 407: 0.9857165650861734,\n",
       " 408: 0.994496994198923,\n",
       " 409: 0.9862828912516813,\n",
       " 410: 0.9827586097597258,\n",
       " 411: 0.5,\n",
       " 412: 0.5,\n",
       " 413: 0.9334296016596882,\n",
       " 414: 0.5,\n",
       " 415: 0.9373578657395382,\n",
       " 416: 0.988623273399542,\n",
       " 417: 0.8888888888888888,\n",
       " 418: 0.9921752704160955,\n",
       " 419: 0.5,\n",
       " 420: 0.7999999999958342,\n",
       " 421: 0.8570344486555693,\n",
       " 422: 0.9975069057860351,\n",
       " 423: 0.9962123605300344,\n",
       " 424: 0.9230766297594994,\n",
       " 425: 0.8571421064972083,\n",
       " 426: 0.9714283924111242,\n",
       " 427: 0.9936426223921865,\n",
       " 428: 0.7499999999971724,\n",
       " 429: 0.9714819038804379,\n",
       " 430: 0.8333333333333333,\n",
       " 431: 0.974362605461264,\n",
       " 432: 0.8999997662763894,\n",
       " 433: 0.9444398692312359,\n",
       " 434: 0.9012741974102361,\n",
       " 435: 0.99445373602457,\n",
       " 436: 0.9836039933281538,\n",
       " 437: 0.6666666666666666,\n",
       " 438: 0.996077158457832,\n",
       " 439: 0.7999936977485173,\n",
       " 440: 0.9844019095551103,\n",
       " 441: 0.9826382681740272,\n",
       " 442: 0.9940469473904132,\n",
       " 443: 0.9333331468600639,\n",
       " 444: 0.9827576455927197,\n",
       " 445: 0.9066391496091487,\n",
       " 446: 0.8,\n",
       " 447: 0.749999999992141,\n",
       " 448: 0.9411764615475952,\n",
       " 449: 0.9090884737382615,\n",
       " 450: 0.9230769145080574,\n",
       " 451: 0.9090881187293484,\n",
       " 452: 0.972220372748698,\n",
       " 453: 0.9743584098484929,\n",
       " 454: 0.9444460509998708,\n",
       " 455: 0.8999999999996632,\n",
       " 456: 0.9836414212695643,\n",
       " 457: 0.9743556397720565,\n",
       " 458: 0.9166651715020927,\n",
       " 459: 0.991805430038515,\n",
       " 460: 0.875,\n",
       " 461: 0.9969327876429775,\n",
       " 462: 0.923076908546505,\n",
       " 463: 0.9924618717845387,\n",
       " 464: 0.9625201117643007,\n",
       " 465: 0.9278671469546201,\n",
       " 466: 0.5,\n",
       " 467: 0.8333288678972575,\n",
       " 468: 0.9090908866078505,\n",
       " 469: 0.9936287118572279,\n",
       " 470: 0.9333328134102076,\n",
       " 471: 0.7497409921883195,\n",
       " 472: 0.8999999999819495,\n",
       " 473: 0.9890525331221534,\n",
       " 474: 0.980371181765103,\n",
       " 475: 0.8890066529471082,\n",
       " 476: 0.8999950094018676,\n",
       " 477: 0.8571428571428571,\n",
       " 478: 0.973684061404735,\n",
       " 479: 0.9761934826261489,\n",
       " 480: 0.9973394184461649,\n",
       " 481: 0.9333294587285399,\n",
       " 482: 0.9333258150280083,\n",
       " 483: 0.9930174230243922,\n",
       " 484: 0.9942197279741536,\n",
       " 485: 0.9687490569111665,\n",
       " 486: 0.8888888872982049,\n",
       " 487: 0.9807684016745143,\n",
       " 488: 0.9743578898833093,\n",
       " 489: 0.967824215160236,\n",
       " 490: 0.9930068104502513,\n",
       " 491: 0.9949609660630601,\n",
       " 492: 0.93333317543071,\n",
       " 493: 0.9907402557394015,\n",
       " 494: 0.7498143291068217,\n",
       " 495: 0.9944250380880703,\n",
       " 496: 0.9333317155367715,\n",
       " 497: 0.8749999999922673,\n",
       " 498: 0.75,\n",
       " 499: 0.7499999999999988,\n",
       " 500: 0.9925902607487221,\n",
       " 501: 0.9827578503851598,\n",
       " 502: 0.6666666666666666,\n",
       " 503: 0.9166665710475629,\n",
       " 504: 0.9605394794324248,\n",
       " 505: 0.9285714285713983,\n",
       " 506: 0.9374930989820396,\n",
       " 507: 0.9090889523133092,\n",
       " 508: 0.9824530186958115,\n",
       " 509: 0.9919990827930502,\n",
       " 510: 0.9892416487908,\n",
       " 511: 0.9899387223470782,\n",
       " 512: 0.9886687936084987,\n",
       " 513: 0.9904759017229128,\n",
       " 514: 0.8333333333333333,\n",
       " 515: 0.9963203321823362,\n",
       " 516: 0.9705632961668396,\n",
       " 517: 0.9862998847390353,\n",
       " 518: 0.9924536359715421,\n",
       " 519: 0.5,\n",
       " 520: 0.9444432021959512,\n",
       " 521: 0.7499797254102437,\n",
       " 522: 0.6666666666666666,\n",
       " 523: 0.49999999999360295,\n",
       " 524: 0.9560994369672199,\n",
       " 525: 0.9765918023968301,\n",
       " 526: 0.9922270085760413,\n",
       " 527: 0.8749999999961461,\n",
       " 528: 0.9944462425672448,\n",
       " 529: 0.9866716097307618,\n",
       " 530: 0.9473667961566526,\n",
       " 531: 0.9955492202643984,\n",
       " 532: 0.5,\n",
       " 533: 0.9934595828118162,\n",
       " 534: 0.9599994311724434,\n",
       " 535: 0.994216617154436,\n",
       " 536: 0.933333333332526,\n",
       " 537: 0.9705831825063034,\n",
       " 538: 0.9545453613920586,\n",
       " 539: 0.9629622900522082,\n",
       " 540: 0.9499999935137591,\n",
       " 541: 0.9824113708767325,\n",
       " 542: 0.7499993825348658,\n",
       " 543: 0.75,\n",
       " 544: 0.6666666666666666,\n",
       " 545: 0.9411747259204507,\n",
       " 546: 0.9473750574315621,\n",
       " 547: 0.75,\n",
       " 548: 0.9914330559203313,\n",
       " 549: 0.941175510376993,\n",
       " 550: 0.9615381011281614,\n",
       " 551: 0.9287501338439038,\n",
       " 552: 0.9945047882690276,\n",
       " 553: 0.9883755006268855,\n",
       " 554: 0.8749999997579722,\n",
       " 555: 0.9772736916396619,\n",
       " 556: 0.9949138269849426,\n",
       " 557: 0.991299948581789,\n",
       " 558: 0.9931978922340986,\n",
       " 559: 0.9989394663100634,\n",
       " 560: 0.9772723620650996,\n",
       " 561: 0.9835932883340877,\n",
       " 562: 0.9166648006979622,\n",
       " 563: 0.9166665447805158,\n",
       " 564: 0.6666666666591063,\n",
       " 565: 0.9687449348962602,\n",
       " 566: 0.9977305841023146,\n",
       " 567: 0.9089550123532515,\n",
       " 568: 0.874999989597881,\n",
       " 569: 0.9374999964608858,\n",
       " 570: 0.9950217988104096,\n",
       " 571: 0.991602169482512,\n",
       " 572: 0.9889881176411953,\n",
       " 573: 0.9940255918326774,\n",
       " 574: 0.8999938327234739,\n",
       " 575: 0.991639561743145,\n",
       " 576: 0.8749977657793881,\n",
       " 577: 0.9677368129384298,\n",
       " 578: 0.9811306943356733,\n",
       " 579: 0.9968257337462523,\n",
       " 580: 0.9926618400924119,\n",
       " 581: 0.75,\n",
       " 582: 0.75,\n",
       " 583: 0.9285590929888299,\n",
       " 584: 0.9375567789953569,\n",
       " 585: 0.9906498293202247,\n",
       " 586: 0.8748883468705516,\n",
       " 587: 0.7999977851138905,\n",
       " 588: 0.9928808534320605,\n",
       " 589: 0.9583330154092796,\n",
       " 590: 0.9885057471264302,\n",
       " 591: 0.8999984147712974,\n",
       " 592: 0.9901812361517993,\n",
       " 593: 0.6666666666556015,\n",
       " 594: 0.75,\n",
       " 595: 0.9938392358483971,\n",
       " 596: 0.9285710491077123,\n",
       " 597: 0.9615967720439722,\n",
       " 598: 0.8333333333197247,\n",
       " 599: 0.9666726850235682,\n",
       " 600: 0.9969238042759383,\n",
       " 601: 0.9749997293122278,\n",
       " 602: 0.9333333054480407,\n",
       " 603: 0.9933174383895792,\n",
       " 604: 0.9982723914999185,\n",
       " 605: 0.9878041198134015,\n",
       " 606: 0.952400104076638,\n",
       " 607: 0.9944183111662381,\n",
       " 608: 0.9379391967647488,\n",
       " 609: 0.991326865019076,\n",
       " 610: 0.9891268979229488,\n",
       " 611: 0.8749998582212022,\n",
       " 612: 0.9849430026031953,\n",
       " 613: 0.8999993678045191,\n",
       " 614: 0.9976312034025059,\n",
       " 615: 0.9772718117611732,\n",
       " 616: 0.5,\n",
       " 617: 0.9565213247961964,\n",
       " 618: 0.5,\n",
       " 619: 0.8333333333333333,\n",
       " 620: 0.9843734676434187,\n",
       " 621: 0.9285652731294917,\n",
       " 622: 0.6666666663648271,\n",
       " 623: 0.9974455940350009,\n",
       " 624: 0.9903840082538571,\n",
       " 625: 0.9977206162553539,\n",
       " 626: 0.9473667642598493,\n",
       " 627: 0.9970730777562409,\n",
       " 628: 0.9443181266046181,\n",
       " 629: 0.9743589231411885,\n",
       " 630: 0.9230768391451423,\n",
       " 631: 0.9824489494721074,\n",
       " 632: 0.9861150510073369,\n",
       " 633: 0.9879760256316705,\n",
       " 634: 0.9830492641056523,\n",
       " 635: 0.7999996385637757,\n",
       " 636: 0.9777774980799535,\n",
       " 637: 0.7499999999059611,\n",
       " 638: 0.75,\n",
       " 639: 0.9922441290839904,\n",
       " 640: 0.9976547007543894,\n",
       " 641: 0.9749968899002683,\n",
       " 642: 0.9985336024630386,\n",
       " 643: 0.9894724754603399,\n",
       " 644: 0.8999999546260151,\n",
       " 645: 0.9941070634406771,\n",
       " 646: 0.954545397556566,\n",
       " 647: 0.9984326368987759,\n",
       " 648: 0.9411736810917146,\n",
       " 649: 0.888888864519661,\n",
       " 650: 0.9642855972796773,\n",
       " 651: 0.9411760219220077,\n",
       " 652: 0.8571423030547147,\n",
       " 653: 0.9565202061206577,\n",
       " 654: 0.9897559785920831,\n",
       " 655: 0.986606231779138,\n",
       " 656: 0.9599994603054589,\n",
       " 657: 0.9230767750189641,\n",
       " 658: 0.9285714272911523,\n",
       " 659: 0.6666666666666666,\n",
       " 660: 0.75,\n",
       " 661: 0.9,\n",
       " 662: 0.8987214298630312,\n",
       " 663: 0.9333297992871267,\n",
       " 664: 0.5,\n",
       " 665: 0.9976255122150617,\n",
       " 666: 0.9554129141115375,\n",
       " 667: 0.9475264426523307,\n",
       " 668: 0.9864790177213398,\n",
       " 669: 0.5,\n",
       " 670: 0.9473682603868557,\n",
       " 671: 0.950728898976951,\n",
       " 672: 0.933643530932443,\n",
       " 673: 0.9740280302169037,\n",
       " 674: 0.9977925451956071,\n",
       " 675: 0.8571427340648977,\n",
       " 676: 0.9715977200216709,\n",
       " 677: 0.8999979619687822,\n",
       " 678: 0.968835653135712,\n",
       " 679: 0.9705332394511678,\n",
       " 680: 0.9230768553055418,\n",
       " 681: 0.9583329280791505,\n",
       " 682: 0.9898408538600042,\n",
       " 683: 0.958332535414375,\n",
       " 684: 0.9642853381523688,\n",
       " 685: 0.8888888888823411,\n",
       " 686: 0.9782590358104476,\n",
       " 687: 0.9969122406150016,\n",
       " 688: 0.9281024489530891,\n",
       " 689: 0.9787228144276204,\n",
       " 690: 0.961530381097182,\n",
       " 691: 0.8749987067445615,\n",
       " 692: 0.9955769003069893,\n",
       " 693: 0.9976688991386323,\n",
       " 694: 0.8999998387938324,\n",
       " 695: 0.9873341305733013,\n",
       " 696: 0.9913691922312303,\n",
       " 697: 0.9873383797200288,\n",
       " 698: 0.9954615305171644,\n",
       " 699: 0.98722264364889,\n",
       " 700: 0.9907396200319577,\n",
       " 701: 0.6666666666661285,\n",
       " 702: 0.9411762952033511,\n",
       " 703: 0.9890646271801742,\n",
       " 704: 0.9444437960523461,\n",
       " 705: 0.9957438622576509,\n",
       " 706: 0.9805528556419574,\n",
       " 707: 0.75,\n",
       " 708: 0.9615384335830708,\n",
       " 709: 0.9945297743623536,\n",
       " 710: 0.75,\n",
       " 711: 0.9897999603854332,\n",
       " 712: 0.833333333313433,\n",
       " 713: 0.9583324983200469,\n",
       " 714: 0.9962867250144871,\n",
       " 715: 0.9928388560926326,\n",
       " 716: 0.9883619899021694,\n",
       " 717: 0.9934616939868555,\n",
       " 718: 0.9166665477465372,\n",
       " 719: 0.9906339731020267,\n",
       " 720: 0.9888867822325125,\n",
       " 721: 0.9876403654266254,\n",
       " 722: 0.9545454542065044,\n",
       " 723: 0.9473482667359218,\n",
       " 724: 0.9677516779094694,\n",
       " 725: 0.9858770735812452,\n",
       " 726: 0.888884503947859,\n",
       " 727: 0.9968543290811374,\n",
       " 728: 0.9767410219547293,\n",
       " 729: 0.9934849072022338,\n",
       " 730: 0.9705527467638211,\n",
       " 731: 0.5,\n",
       " 732: 0.9885112296991017,\n",
       " 733: 0.998538480203262,\n",
       " 734: 0.9731375992924879,\n",
       " 735: 0.9872057644058065,\n",
       " 736: 0.9333331084942641,\n",
       " 737: 0.9565213895532203,\n",
       " 738: 0.5,\n",
       " 739: 0.5,\n",
       " 740: 0.6666666666666666,\n",
       " 741: 0.5,\n",
       " 742: 0.9973468232017446,\n",
       " 743: 0.9736838919700777,\n",
       " 744: 0.9444439308604902,\n",
       " 745: 0.5,\n",
       " 746: 0.7999999999922157,\n",
       " 747: 0.9782657859384696,\n",
       " 748: 0.5,\n",
       " 749: 0.9599989730374727,\n",
       " 750: 0.9982630424795392,\n",
       " 751: 0.9924081880562091,\n",
       " 752: 0.5,\n",
       " 753: 0.987804630934187,\n",
       " 754: 0.9967614048470407,\n",
       " 755: 0.8,\n",
       " 756: 0.9819624887496353,\n",
       " 757: 0.9411764496858965,\n",
       " 758: 0.9827579640331935,\n",
       " 759: 0.9371900751285556,\n",
       " 760: 0.9965748349272551,\n",
       " 761: 0.9932348310682478,\n",
       " 762: 0.8318375562199566,\n",
       " 763: 0.9677306278436362,\n",
       " 764: 0.9848464790233596,\n",
       " 765: 0.9974488226779512,\n",
       " 766: 0.974733695856723,\n",
       " 767: 0.9965854247559509,\n",
       " 768: 0.9928518745051211,\n",
       " 769: 0.5,\n",
       " 770: 0.6666666666666666,\n",
       " 771: 0.8749999999108621,\n",
       " 772: 0.979058114917707,\n",
       " 773: 0.9283329431928916,\n",
       " 774: 0.9919294130818989,\n",
       " 775: 0.995883049088847,\n",
       " 776: 0.9969042598091878,\n",
       " 777: 0.9970390700742101,\n",
       " 778: 0.9666641573006787,\n",
       " 779: 0.995736524288943,\n",
       " 780: 0.975608835103125,\n",
       " 781: 0.8999999365449742,\n",
       " 782: 0.5,\n",
       " 783: 0.974986154869353,\n",
       " 784: 0.9473678698298832,\n",
       " 785: 0.6666666666666666,\n",
       " 786: 0.9545444783653344,\n",
       " 787: 0.9529877966025331,\n",
       " 788: 0.9963450711765003,\n",
       " 789: 0.9773887880525078,\n",
       " 790: 0.9766848751722531,\n",
       " 791: 0.7999899106168141,\n",
       " 792: 0.9838651112837934,\n",
       " 793: 0.9827500458546334,\n",
       " 794: 0.9305271160686815,\n",
       " 795: 0.5,\n",
       " 796: 0.8885396216603174,\n",
       " 797: 0.988655543895412,\n",
       " 798: 0.9411738987797512,\n",
       " 799: 0.9884605102312823,\n",
       " 800: 0.9285699440424154,\n",
       " 801: 0.949998221080976,\n",
       " 802: 0.5,\n",
       " 803: 0.9888435261291965,\n",
       " 804: 0.9615381712017587,\n",
       " 805: 0.9230765711858097,\n",
       " 806: 0.9848464291038372,\n",
       " 807: 0.9782608294054629,\n",
       " 808: 0.8749999991296726,\n",
       " 809: 0.9898025009941858,\n",
       " 810: 0.5,\n",
       " 811: 0.9767441464409761,\n",
       " 812: 0.9677411189472608,\n",
       " 813: 0.7999995080359574,\n",
       " 814: 0.9722295630546385,\n",
       " 815: 0.9973445476380401,\n",
       " 816: 0.9545416450145598,\n",
       " 817: 0.8749997791658681,\n",
       " 818: 0.9782742688275052,\n",
       " 819: 0.9932947901555773,\n",
       " 820: 0.9979928382192721,\n",
       " 821: 0.9909906460527974,\n",
       " 822: 0.9953029946457091,\n",
       " 823: 0.9931655970857065,\n",
       " 824: 0.9865887910540969,\n",
       " 825: 0.5,\n",
       " 826: 0.9943725027257434,\n",
       " 827: 0.9743570554886406,\n",
       " 828: 0.8003948192323254,\n",
       " 829: 0.9850719239419741,\n",
       " 830: 0.9583285201021565,\n",
       " 831: 0.9624069925594418,\n",
       " 832: 0.9866036676407055,\n",
       " 833: 0.9945371861159986,\n",
       " 834: 0.9978512546606241,\n",
       " 835: 0.9924196002310384,\n",
       " 836: 0.49999999999999994,\n",
       " 837: 0.982241691100949,\n",
       " 838: 0.9444424292962365,\n",
       " 839: 0.9444437971332423,\n",
       " 840: 0.9915140550197801,\n",
       " 841: 0.9944270629101148,\n",
       " 842: 0.9583330978488616,\n",
       " 843: 0.9615127330213595,\n",
       " 844: 0.7499986072701493,\n",
       " 845: 0.9878983054312298,\n",
       " 846: 0.9921190145352083,\n",
       " 847: 0.9090908674945566,\n",
       " 848: 0.7499999446381956,\n",
       " 849: 0.9952549218601563,\n",
       " 850: 0.9714283140061847,\n",
       " 851: 0.9772701759765262,\n",
       " 852: 0.9781895279365636,\n",
       " 853: 0.9484616138317192,\n",
       " 854: 0.909090909079899,\n",
       " 855: 0.9948919376881812,\n",
       " 856: 0.5,\n",
       " 857: 0.9957628819600278,\n",
       " 858: 0.9973790889624222,\n",
       " 859: 0.6666666666666666,\n",
       " 860: 0.9945298339064808,\n",
       " 861: 0.8888888878142288,\n",
       " 862: 0.9627603030337225,\n",
       " 863: 0.8749999158665726,\n",
       " 864: 0.833332926516707,\n",
       " 865: 0.9819939294673365,\n",
       " 866: 0.8999996839543569,\n",
       " 867: 0.9859144579321655,\n",
       " 868: 0.9953025168268168,\n",
       " 869: 0.9253961502343642,\n",
       " 870: 0.9599999250598921,\n",
       " 871: 0.9696953034454749,\n",
       " 872: 0.8333333329629242,\n",
       " 873: 0.6666664160571287,\n",
       " 874: 0.991331363193263,\n",
       " 875: 0.9374992732756422,\n",
       " 876: 0.8333332088596083,\n",
       " 877: 0.8582760785416821,\n",
       " 878: 0.9843737512038334,\n",
       " 879: 0.6666666666657438,\n",
       " 880: 0.9523809453140561,\n",
       " 881: 0.49999998832367226,\n",
       " 882: 0.9974784586144059,\n",
       " 883: 0.9499967210856634,\n",
       " 884: 0.5,\n",
       " 885: 0.49999642031649105,\n",
       " 886: 0.958331255624754,\n",
       " 887: 0.9090879160355338,\n",
       " 888: 0.9785951403688441,\n",
       " 889: 0.9957039262606409,\n",
       " 890: 0.9677240614001695,\n",
       " 891: 0.9839105666730202,\n",
       " 892: 0.9374474216494212,\n",
       " 893: 0.9963443290362374,\n",
       " 894: 0.8333310844980805,\n",
       " 895: 0.75,\n",
       " 896: 0.9977067672450625,\n",
       " 897: 0.9934372797372687,\n",
       " 898: 0.666666115429575,\n",
       " 899: 0.9090897960584687,\n",
       " 900: 0.9696896943037862,\n",
       " 901: 0.7999995466957351,\n",
       " 902: 0.9285847061682336,\n",
       " 903: 0.5,\n",
       " 904: 0.9934628653760003,\n",
       " 905: 0.9956545665477388,\n",
       " 906: 0.666666666517409,\n",
       " 907: 0.9473539798555767,\n",
       " 908: 0.8749987363160375,\n",
       " 909: 0.9166666603910547,\n",
       " 910: 0.9944782549565407,\n",
       " 911: 0.9782577734669399,\n",
       " 912: 0.9937319616331621,\n",
       " 913: 0.9969854700383021,\n",
       " 914: 0.9964225757140304,\n",
       " 915: 0.9879514083152376,\n",
       " 916: 0.5,\n",
       " 917: 0.7999999999982879,\n",
       " 918: 0.980653814024413,\n",
       " 919: 0.8,\n",
       " 920: 0.8,\n",
       " 921: 0.8999885766670622,\n",
       " 922: 0.9961299763287318,\n",
       " 923: 0.9935460380218883,\n",
       " 924: 0.6666666666666666,\n",
       " 925: 0.5,\n",
       " 926: 0.9885048752645927,\n",
       " 927: 0.5,\n",
       " 928: 0.9791374065469989,\n",
       " 929: 0.5,\n",
       " 930: 0.9090909090909005,\n",
       " 931: 0.9950071650095008,\n",
       " 932: 0.9896562945806294,\n",
       " 933: 0.5,\n",
       " 934: 0.9903816821378747,\n",
       " 935: 0.9725581013951232,\n",
       " 936: 0.8749998406688305,\n",
       " 937: 0.6666666666666666,\n",
       " 938: 0.75,\n",
       " 939: 0.6666666666666666,\n",
       " 940: 0.9899569595015912,\n",
       " 941: 0.9714262588062089,\n",
       " 942: 0.9907326921401484,\n",
       " 943: 0.8333333333332151,\n",
       " 944: 0.9817158370667723,\n",
       " 945: 0.9879582597309636,\n",
       " 946: 0.9910697889332414,\n",
       " 947: 0.9374982288770859,\n",
       " 948: 0.9990072946088265,\n",
       " 949: 0.9767422635119293,\n",
       " 950: 0.9706309838071354,\n",
       " 951: 0.8999999865676764,\n",
       " 952: 0.9939712098260576,\n",
       " 953: 0.99571613909823,\n",
       " 954: 0.9473682622229197,\n",
       " 955: 0.9655073636238033,\n",
       " 956: 0.9582692259827681,\n",
       " 957: 0.9687499616269737,\n",
       " 958: 0.9968007584161107,\n",
       " 959: 0.9954128622032355,\n",
       " 960: 0.8888873470335854,\n",
       " 961: 0.9499999820514277,\n",
       " 962: 0.9859139145296855,\n",
       " 963: 0.9879482451883597,\n",
       " 964: 0.5,\n",
       " 965: 0.9859152809715473,\n",
       " 966: 0.8888888888884416,\n",
       " 967: 0.8571428079215201,\n",
       " 968: 0.9374992243324437,\n",
       " 969: 0.9926124485751043,\n",
       " 970: 0.9473671399645747,\n",
       " 971: 0.9960674041850707,\n",
       " 972: 0.9817985400041459,\n",
       " 973: 0.9565217077217333,\n",
       " 974: 0.9166665629627075,\n",
       " 975: 0.9220887019672557,\n",
       " 976: 0.9653470887623493,\n",
       " 977: 0.9967342533067869,\n",
       " 978: 0.997911342555519,\n",
       " 979: 0.9813632075270735,\n",
       " 980: 0.9285714252382259,\n",
       " 981: 0.6666666666666666,\n",
       " 982: 0.9859100589677542,\n",
       " 983: 0.799999736923602,\n",
       " 984: 0.9965316280031874,\n",
       " 985: 0.970590679997295,\n",
       " 986: 0.9230767062490296,\n",
       " 987: 0.958329757150047,\n",
       " 988: 0.9955458856571394,\n",
       " 989: 0.7499999999991902,\n",
       " 990: 0.973706259775565,\n",
       " 991: 0.8333333314851966,\n",
       " 992: 0.9583317665107736,\n",
       " 993: 0.5,\n",
       " 994: 0.9968685329478187,\n",
       " 995: 0.9852940488771748,\n",
       " 996: 0.9966904455282131,\n",
       " 997: 0.9615340654054463,\n",
       " 998: 0.6666653576829498,\n",
       " 999: 0.9846012025296784,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_expecs = linGreedy_model.mab.predict_expectations([contexts[0]])\n",
    "old_expecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_expecs.tolist() == list(old_expecs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = get_concat_context(df_test_for_evaluation, ['items_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando as predições\n",
      "Gerar as predições demorou 4.0329015254974365 segundos\n"
     ]
    }
   ],
   "source": [
    "new_expecs = mab_arm_encoded.predict_expectations(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando as predições\n",
      "Gerar as predições demorou 2.9999358654022217 segundos\n",
      "Formatando as predições\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:14<00:00, 266.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatação demorou 14.264642000198364 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_expecs = linGreedy_model.mab.predict_expectations(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_expecs.tolist() == [list(expec.values()) for expec in old_expecs]  # Talvez tenha alguma pequena mudança numérica na hora de conversão ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Union\n",
    "from mabwiser.utils import Arm, Num, _BaseRNG\n",
    "\n",
    "class BanditRecommenderArmEncoded(BanditRecommender):\n",
    "    def _init(self, num_arms: int) -> None:\n",
    "        \"\"\"Initializes recommender with given list of arms.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        arms : List[Union[Arm]]\n",
    "            The list of all of the arms available for decisions.\n",
    "            Arms can be integers, strings, etc.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Returns nothing\n",
    "        \"\"\"\n",
    "        self.mab = MABArmEncoded(num_arms, self.learning_policy, self.neighborhood_policy, self.seed, self.n_jobs, self.backend)\n",
    "    \n",
    "    def fit(self, decisions: Union[List[Arm], np.ndarray, pd.Series],\n",
    "            rewards: Union[List[Num], np.ndarray, pd.Series],\n",
    "            contexts: Union[None, List[List[Num]], np.ndarray, pd.Series, pd.DataFrame] = None) -> None:\n",
    "        \"\"\"Fits the recommender the given *decisions*, their corresponding *rewards* and *contexts*, if any.\n",
    "        If the recommender arms has not been initialized using the `set_arms`, the recommender arms will be set\n",
    "        to the list of arms in *decisions*.\n",
    "\n",
    "        Validates arguments and raises exceptions in case there are violations.\n",
    "\n",
    "        This function makes the following assumptions:\n",
    "            - each decision corresponds to an arm of the bandit.\n",
    "            - there are no ``None``, ``Nan``, or ``Infinity`` values in the contexts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "         decisions : Union[List[Arm], np.ndarray, pd.Series]\n",
    "            The decisions that are made.\n",
    "         rewards : Union[List[Num], np.ndarray, pd.Series]\n",
    "            The rewards that are received corresponding to the decisions.\n",
    "         contexts : Union[None, List[List[Num]], np.ndarray, pd.Series, pd.DataFrame], default=None\n",
    "            The context under which each decision is made.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Returns nothing.\n",
    "        \"\"\"\n",
    "        if self.mab is None:\n",
    "            self._init(np.unique(decisions).shape[0])\n",
    "        self.mab.fit(decisions, rewards, contexts)\n",
    "    \n",
    "    def recommend(self, contexts: Union[None, List[List[Num]], np.ndarray, pd.Series, pd.DataFrame] = None,\n",
    "                  excluded_arms: List[List[Arm]] = None, return_scores: bool = False, apply_sigmoid: bool = True) \\\n",
    "            -> Union[Union[List[Arm], Tuple[List[Arm], List[Num]],\n",
    "                     Union[List[List[Arm]], Tuple[List[List[Arm]], List[List[Num]]]]]]:\n",
    "        self._validate_mab(is_fit=True)\n",
    "        self._validate_get_rec(contexts, excluded_arms)\n",
    "\n",
    "        print('oi1')\n",
    "        start_time = time.time()\n",
    "        # Get predicted expectations\n",
    "        num_contexts = len(contexts) if contexts is not None else 1\n",
    "        if num_contexts == 1:\n",
    "            expectations = [self.mab.predict_expectations(contexts)]\n",
    "        else:\n",
    "            expectations = self.mab.predict_expectations(contexts)\n",
    "        print(f'predict_expectations demorou {time.time() - start_time} segundos')\n",
    "        print('oi2')\n",
    "\n",
    "        # Create an exclusion mask, where exclusion_mask[context_ind][arm_ind] denotes if the arm with the\n",
    "        # index arm_ind was excluded for context with the index context_ind.\n",
    "        # The value will be True if it is excluded and those arms will not be returned as part of the results.\n",
    "        print('criando matriz de exclusão de arms')\n",
    "        arm_to_index = {arm: arm_ind for arm_ind, arm in enumerate(self.mab.arms)}\n",
    "        exclude_mask = np.zeros((num_contexts, len(self.mab.arms)), dtype=bool)\n",
    "        if excluded_arms is not None:\n",
    "            for context_ind, excluded in tqdm(enumerate(excluded_arms), total=len(excluded_arms)):\n",
    "                exclude_mask[context_ind][[arm_to_index[arm] for arm in excluded if arm in arm_to_index]] = True\n",
    "\n",
    "        print('fazendo o restante')\n",
    "        start_time = time.time()\n",
    "        # Set excluded item scores to -1, so they automatically get placed lower in best results\n",
    "        expectations[exclude_mask] = -1.\n",
    "\n",
    "        # Get best `top_k` results by sorting the expectations\n",
    "        arm_inds = np.flip(np.argsort(expectations)[:, -self.top_k:], axis=1)\n",
    "\n",
    "        # Get the list of top_k recommended items and corresponding expectations for each context\n",
    "        recommendations = [[]] * num_contexts\n",
    "        scores = [[]] * num_contexts\n",
    "        for context_ind in range(num_contexts):\n",
    "            recommendations[context_ind] = [self.mab.arms[arm_ind] for arm_ind in arm_inds[context_ind]\n",
    "                                            if not exclude_mask[context_ind, arm_ind]]\n",
    "            if return_scores:\n",
    "                scores[context_ind] = [expectations[context_ind, arm_ind] for arm_ind in arm_inds[context_ind]\n",
    "                                       if not exclude_mask[context_ind, arm_ind]]\n",
    "\n",
    "        print(f'O restante demorou {time.time() - start_time} segundos')\n",
    "        # Return recommendations and scores\n",
    "        if return_scores:\n",
    "            if num_contexts > 1:\n",
    "                return recommendations, scores\n",
    "            else:\n",
    "                return recommendations[0], scores[0]\n",
    "        else:\n",
    "            if num_contexts > 1:\n",
    "                return recommendations\n",
    "            else:\n",
    "                return recommendations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinGreedy - ALS embeddings\n",
      "arm_to_model demorou -0.3791170120239258\n",
      "reset_arm_to_status demorou -0.01372838020324707\n",
      "paralel fit demorou -21.17717933654785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_set_arms_as_trained acabou em -19.91711449623108 segundos\n",
      "Treino demorou 45.66488790512085\n",
      "Testing LinGreedy - ALS embeddings\n",
      "entrou\n",
      "saiu\n",
      "oi1\n",
      "Gerando as predições\n",
      "Gerar as predições demorou 3.181675910949707 segundos\n",
      "predict_expectations demorou 3.208477020263672 segundos\n",
      "oi2\n",
      "criando matriz de exclusão de arms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 283329.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fazendo o restante\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O restante demorou 8.084055185317993 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3799/3799 [00:00<00:00, 16001.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Training LinGreedy - ALS embeddings')\n",
    "linGreedy_model = BanditRecommenderArmEncoded(learning_policy=LearningPolicy.LinGreedy(epsilon=0.01), top_k=10)\n",
    "start_time = time.time()\n",
    "train_mab(linGreedy_model, current_df_train, ['items_mean'])\n",
    "print(f'Treino demorou {time.time() - start_time}')\n",
    "\n",
    "print(f'Testing LinGreedy - ALS embeddings')\n",
    "hits, hr, spent_time, df_recs_linGreedy = test_non_incremental(linGreedy_model, ['items_mean'], df_test_for_evaluation, interactions_by_user)\n",
    "hits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLRS-rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
