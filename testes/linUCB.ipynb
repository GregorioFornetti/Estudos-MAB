{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinUCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse notebook está sendo utilizado para entender melhor sobre o algoritmo LinUCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando em um cenário simples, apenas dois possíveis arms e dois contextos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executando de forma não interativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o braço 1:\n",
    "\n",
    "# Contextos\n",
    "X_1 = np.array([\n",
    "    [0], [0], [0], [0], [0], [0], [0], [0], [0], [0],\n",
    "    [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]\n",
    "])\n",
    "\n",
    "# Recompensas\n",
    "y_1 = np.array([\n",
    "    [1], [1], [1], [1], [1], [1], [1], [1], [0], [0],\n",
    "    [0], [0], [0], [0], [0], [0], [0], [0], [1], [1]\n",
    "])\n",
    "\n",
    "# Escolher o arm 1 no contexto 0 leva à 80% de chance de recompensa 1, e 20% de chance de recompensa 0\n",
    "# Escolher o arm 1 no contexto 1 leva à 20% de chance de recompensa 1, e 80% de chance de recompensa 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o braço 2:\n",
    "\n",
    "# Contextos\n",
    "X_2 = np.array([\n",
    "    [0], [0], [0], [0], [0], [0], [0], [0], [0], [0],\n",
    "    [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]\n",
    "])\n",
    "\n",
    "# Recompensas\n",
    "y_2 = np.array([\n",
    "    [0], [0], [0], [0], [0], [0], [0], [0], [1], [1],\n",
    "    [1], [1], [1], [1], [1], [1], [1], [1], [0], [0]\n",
    "])\n",
    "\n",
    "# Escolher o arm 1 no contexto 0 leva à 20% de chance de recompensa 1, e 80% de chance de recompensa 0\n",
    "# Escolher o arm 1 no contexto 1 leva à 80% de chance de recompensa 1, e 20% de chance de recompensa 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_params_by_OLS(x: np.ndarray, y: np.ndarray, use_identity: bool = False):\n",
    "    \"\"\"\n",
    "    Calculate the parameters w and b using the Ordinary Least Squares method\n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      y (ndarray (m,)): target values\n",
    "    Returns:\n",
    "      w, b (scalar): model parameters\n",
    "    \"\"\"\n",
    "    x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "    x_transpose = x.T\n",
    "\n",
    "    if use_identity:\n",
    "        w = np.linalg.inv(x_transpose.dot(x) + np.identity(x.shape[1])).dot(x_transpose).dot(y)\n",
    "    else:\n",
    "        w = np.linalg.inv(x_transpose.dot(x)).dot(x_transpose).dot(y)\n",
    "  \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta para o braço 1: [[-0.6]\n",
      " [ 0.8]]\n",
      "Para o contexto 0, a recompensa esperada é 0.8\n",
      "Para o contexto 1, a recompensa esperada é 0.19999999999999996\n"
     ]
    }
   ],
   "source": [
    "theta_1 = calculate_params_by_OLS(X_1, y_1, use_identity=False)\n",
    "\n",
    "print(f\"Theta para o braço 1: {theta_1}\")\n",
    "print(f\"Para o contexto 0, a recompensa esperada é {np.array([0, 1]).dot(theta_1)[0]}\")  # Precisa adicionar o 1 no final do vetor de contexto, ele é o bias (intercept)\n",
    "print(f\"Para o contexto 1, a recompensa esperada é {np.array([1, 1]).dot(theta_1)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta para o braço 2: [[0.6]\n",
      " [0.2]]\n",
      "Para o contexto 0, a recompensa esperada é 0.2\n",
      "Para o contexto 1, a recompensa esperada é 0.8\n"
     ]
    }
   ],
   "source": [
    "theta_2 = calculate_params_by_OLS(X_2, y_2, use_identity=False)\n",
    "\n",
    "print(f\"Theta para o braço 2: {theta_2}\")\n",
    "print(f\"Para o contexto 0, a recompensa esperada é {np.array([0, 1]).dot(theta_2)[0]}\")\n",
    "print(f\"Para o contexto 1, a recompensa esperada é {np.array([1, 1]).dot(theta_2)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta para o braço 1: [[-0.44274809]\n",
      " [ 0.6870229 ]]\n",
      "Para o contexto 0, a recompensa esperada é 0.6870229007633588\n",
      "Para o contexto 1, a recompensa esperada é 0.2442748091603053\n"
     ]
    }
   ],
   "source": [
    "theta_1 = calculate_params_by_OLS(X_1, y_1, use_identity=True)\n",
    "\n",
    "print(f\"Theta para o braço 1: {theta_1}\")\n",
    "print(f\"Para o contexto 0, a recompensa esperada é {np.array([0, 1]).dot(theta_1)[0]}\")\n",
    "print(f\"Para o contexto 1, a recompensa esperada é {np.array([1, 1]).dot(theta_1)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta para o braço 2: [[0.51908397]\n",
      " [0.22900763]]\n",
      "Para o contexto 0, a recompensa esperada é 0.22900763358778625\n",
      "Para o contexto 1, a recompensa esperada é 0.748091603053435\n"
     ]
    }
   ],
   "source": [
    "theta_2 = calculate_params_by_OLS(X_2, y_2, use_identity=True)\n",
    "\n",
    "print(f\"Theta para o braço 2: {theta_2}\")\n",
    "print(f\"Para o contexto 0, a recompensa esperada é {np.array([0, 1]).dot(theta_2)[0]}\")\n",
    "print(f\"Para o contexto 1, a recompensa esperada é {np.array([1, 1]).dot(theta_2)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_params_by_OLS_interactive(x, y):\n",
    "    x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "    A = np.identity(x.shape[1])\n",
    "    b = np.zeros((x.shape[1],))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x_t = x[i].reshape(1, -1)\n",
    "        A += x_t.T @ x_t\n",
    "        b += y[i] * x_t[0]\n",
    "    \n",
    "    return (np.linalg.inv(A) @ b).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta para o braço 1: [-0.44274809  0.6870229 ]\n",
      "Para o contexto 0, a recompensa esperada é 0.6870229007633588\n",
      "Para o contexto 1, a recompensa esperada é 0.2442748091603053\n"
     ]
    }
   ],
   "source": [
    "theta_1 = calculate_params_by_OLS_interactive(X_1, y_1)\n",
    "\n",
    "print(f\"Theta para o braço 1: {theta_1}\")\n",
    "print(f\"Para o contexto 0, a recompensa esperada é {np.array([0, 1]).dot(theta_1)}\")\n",
    "print(f\"Para o contexto 1, a recompensa esperada é {np.array([1, 1]).dot(theta_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta para o braço 2: [0.51908397 0.22900763]\n",
      "Para o contexto 0, a recompensa esperada é 0.2290076335877863\n",
      "Para o contexto 1, a recompensa esperada é 0.748091603053435\n"
     ]
    }
   ],
   "source": [
    "theta_2 = calculate_params_by_OLS_interactive(X_2, y_2)\n",
    "\n",
    "print(f\"Theta para o braço 2: {theta_2}\")\n",
    "print(f\"Para o contexto 0, a recompensa esperada é {np.array([0, 1]).dot(theta_2)}\")\n",
    "print(f\"Para o contexto 1, a recompensa esperada é {np.array([1, 1]).dot(theta_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  5.]\n",
      " [ 5. 16.]]\n",
      "[[ 6.  5.]\n",
      " [ 5. 16.]]\n"
     ]
    }
   ],
   "source": [
    "qnt = 15\n",
    "\n",
    "X_1_bias = np.concatenate((X_1, np.ones((X_1.shape[0], 1))), axis=1)\n",
    "identity = np.identity(X_1_bias.shape[1])\n",
    "\n",
    "A_1 = X_1_bias[:qnt].T @ X_1_bias[:qnt] + identity\n",
    "\n",
    "A_1_interactive = identity\n",
    "b_1_interactive = np.zeros((X_1_bias.shape[1],))\n",
    "for i in range(qnt):\n",
    "    x = X_1_bias[i].reshape(1, -1)\n",
    "    A_1_interactive += x.T @ x\n",
    "    b_1_interactive += y_1[i] * x[0]\n",
    "\n",
    "print(A_1)\n",
    "print(A_1_interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_params_by_OLS_interactive(x, y, alpha):\n",
    "    x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "    A = np.identity(x.shape[1])\n",
    "    b = np.zeros((x.shape[1],))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x_t = x[i].reshape(1, -1)\n",
    "        A += x_t.T @ x_t\n",
    "        b += y[i] * x_t[0]\n",
    "\n",
    "        exploration_value = alpha * np.sqrt(x_t @ np.linalg.inv(A) @ x_t.T)\n",
    "        print(exploration_value)\n",
    "    \n",
    "    return (np.linalg.inv(A) @ b).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35355339]]\n",
      "[[0.28867513]]\n",
      "[[0.25]]\n",
      "[[0.2236068]]\n",
      "[[0.20412415]]\n",
      "[[0.18898224]]\n",
      "[[0.1767767]]\n",
      "[[0.16666667]]\n",
      "[[0.15811388]]\n",
      "[[0.15075567]]\n",
      "[[0.36115756]]\n",
      "[[0.29277002]]\n",
      "[[0.25264558]]\n",
      "[[0.22549381]]\n",
      "[[0.20555661]]\n",
      "[[0.19011728]]\n",
      "[[0.17770466]]\n",
      "[[0.16744367]]\n",
      "[[0.15877684]]\n",
      "[[0.15132998]]\n",
      "Theta para o braço 1: [-0.44274809  0.6870229 ]\n",
      "Para o contexto 0, a recompensa esperada é 0.6870229007633588\n",
      "Para o contexto 1, a recompensa esperada é 0.2442748091603053\n"
     ]
    }
   ],
   "source": [
    "theta_1 = calculate_params_by_OLS_interactive(X_1, y_1, 0.5)\n",
    "\n",
    "print(f\"Theta para o braço 1: {theta_1}\")\n",
    "print(f\"Para o contexto 0, a recompensa esperada é {np.array([0, 1]).dot(theta_1)}\")\n",
    "print(f\"Para o contexto 1, a recompensa esperada é {np.array([1, 1]).dot(theta_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35355339]]\n",
      "[[0.28867513]]\n",
      "[[0.25]]\n",
      "[[0.2236068]]\n",
      "[[0.20412415]]\n",
      "[[0.18898224]]\n",
      "[[0.1767767]]\n",
      "[[0.16666667]]\n",
      "[[0.15811388]]\n",
      "[[0.15075567]]\n",
      "[[0.36115756]]\n",
      "[[0.29277002]]\n",
      "[[0.25264558]]\n",
      "[[0.22549381]]\n",
      "[[0.20555661]]\n",
      "[[0.19011728]]\n",
      "[[0.17770466]]\n",
      "[[0.16744367]]\n",
      "[[0.15877684]]\n",
      "[[0.15132998]]\n"
     ]
    }
   ],
   "source": [
    "theta_2 = calculate_params_by_OLS_interactive(X_2, y_2, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLRS-rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
